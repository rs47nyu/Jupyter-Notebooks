{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780d555-9be0-4f7b-8f87-ec97aac6fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001] Time=12.66s | alpha_ft=1.152005, gamma_age_ft=-0.004648, gamma_agesq_ft=0.008459 | Loss=0.065879\n",
      "[002] Time=13.20s | alpha_ft=1.440006, gamma_age_ft=-0.004648, gamma_agesq_ft=0.008459 | Loss=7.243999\n",
      "[003] Time=12.61s | alpha_ft=1.152005, gamma_age_ft=-0.003486, gamma_agesq_ft=0.008459 | Loss=0.168160\n",
      "[004] Time=12.71s | alpha_ft=1.152005, gamma_age_ft=-0.004648, gamma_agesq_ft=0.010574 | Loss=0.105432\n",
      "[005] Time=12.24s | alpha_ft=0.864004, gamma_age_ft=-0.003873, gamma_agesq_ft=0.009869 | Loss=4.225810\n",
      "[006] Time=11.90s | alpha_ft=1.008004, gamma_age_ft=-0.004067, gamma_agesq_ft=0.009516 | Loss=1.054623\n",
      "[007] Time=12.08s | alpha_ft=1.296006, gamma_age_ft=-0.004454, gamma_agesq_ft=0.008811 | Loss=2.077743\n",
      "[008] Time=11.84s | alpha_ft=1.080005, gamma_age_ft=-0.004164, gamma_agesq_ft=0.009340 | Loss=0.248219\n"
     ]
    }
   ],
   "source": [
    "# Structural model estimated by SMM with II\n",
    "# Delta and Bootstrapping methods for standard errors\n",
    "# Auxiliary regressions have state and year fixed effects\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "BASE_DIR = \"/Users/robertsauer/Downloads/Keane/Python/figures\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------- Load and prepare data -------------------------------------------------------\n",
    "\n",
    "df_all = pd.read_stata(\"/Users/robertsauer/Downloads/Keane/Python/indirect_inference_robert.dta\")\n",
    "\n",
    "USE_R_CPI = False  # ðŸ” Toggle to True to use R-CPI-U-RS with 1977=100\n",
    "\n",
    "CPI_1983_BASE = {\n",
    "    1977: 60.6, 1978: 65.2, 1979: 72.6, 1980: 82.4, 1981: 90.9,\n",
    "    1982: 96.5, 1983: 100.0, 1984: 103.9, 1985: 107.6, 1986: 109.6,\n",
    "    1987: 113.6, 1988: 118.3, 1989: 124.0, 1990: 130.7, 1991: 136.2,\n",
    "    1992: 140.3, 1993: 144.5, 1994: 148.2, 1995: 152.4, 1996: 156.9,\n",
    "    1997: 160.5, 1998: 163.0, 1999: 166.6, 2000: 172.2, 2001: 177.1,\n",
    "    2002: 179.9, 2003: 184.0, 2004: 188.9, 2005: 195.3, 2006: 201.6,\n",
    "    2007: 207.3, 2008: 215.3, 2009: 214.5, 2010: 218.1, 2011: 224.9,\n",
    "    2012: 229.6\n",
    "}\n",
    "\n",
    "CPI_1977_BASE = {\n",
    "    1977: 100.0, 1978: 107.8, 1979: 119.5, 1980: 132.4, 1981: 143.4,\n",
    "    1982: 150.6, 1983: 156.3, 1984: 162.3, 1985: 168.1, 1986: 169.6,\n",
    "    1987: 176.5, 1988: 183.4, 1989: 191.1, 1990: 202.0, 1991: 206.8,\n",
    "    1992: 211.9, 1993: 216.7, 1994: 221.4, 1995: 226.4, 1996: 233.4,\n",
    "    1997: 237.0, 1998: 240.3, 1999: 246.8, 2000: 255.1, 2001: 259.1,\n",
    "    2002: 265.3, 2003: 270.3, 2004: 279.1, 2005: 288.6, 2006: 296.0,\n",
    "    2007: 308.1, 2008: 308.3, 2009: 316.7, 2010: 321.5, 2011: 333.1,\n",
    "    2012: 337.0\n",
    "}\n",
    "\n",
    "CPI_BY_YEAR = CPI_1977_BASE if USE_R_CPI else CPI_1983_BASE\n",
    "\n",
    "# State fips code variable\n",
    "df_all[\"stfips\"] = df_all[\"stfips\"].astype(int)\n",
    "\n",
    "# Education variables\n",
    "df_all[\"edu\"] = df_all[\"edu\"].astype(int)\n",
    "df_all[\"edu_2\"] = (df_all[\"edu\"] == 2).astype(int)\n",
    "df_all[\"edu_3\"] = (df_all[\"edu\"] == 3).astype(int)\n",
    "\n",
    "# Employment variables\n",
    "df_all[\"actual_nonemp\"] = (df_all[\"employed_ptft_robert\"] == 0).astype(int)\n",
    "df_all[\"actual_part\"] = (df_all[\"employed_ptft_robert\"] == 1).astype(int)\n",
    "df_all[\"actual_full\"] = (df_all[\"employed_ptft_robert\"] == 2).astype(int)\n",
    "df_all[\"employed\"] = (df_all[\"employed_ptft_robert\"] > 0).astype(int)        # PT or FT vs NE\n",
    "df_all[\"employed_pt\"] = (df_all[\"employed_ptft_robert\"] == 1).astype(int)    # PT vs NE (raw dummy, masking needed)\n",
    "df_all[\"employed_ft\"] = (df_all[\"employed_ptft_robert\"] == 2).astype(int)    # FT vs NE (raw dummy, masking needed)\n",
    "\n",
    "# Children variables\n",
    "df_all[\"children\"] = df_all[\"children\"].astype(int)\n",
    "df_all[\"dum_child\"] = df_all[\"dum_child\"].astype(int)\n",
    "df_all[\"child_0\"] = (df_all[\"children\"] == 0).astype(int)\n",
    "df_all[\"child_1\"] = (df_all[\"children\"] == 1).astype(int)\n",
    "df_all[\"child_2\"] = (df_all[\"children\"] == 2).astype(int)\n",
    "df_all[\"child_3\"] = (df_all[\"children\"] >= 3).astype(int)\n",
    "\n",
    "# Race variables\n",
    "df_all[\"race\"] = df_all[\"race\"].astype(int)\n",
    "df_all[\"race_1\"] = (df_all[\"race\"] == 1).astype(int)  # White\n",
    "df_all[\"race_2\"] = (df_all[\"race\"] == 2).astype(int)  # Black\n",
    "df_all[\"race_3\"] = (df_all[\"race\"] == 3).astype(int)  # Other\n",
    "\n",
    "# Age variables\n",
    "df_all[\"age\"] = df_all[\"age\"].astype(float)\n",
    "df_all[\"agesq\"] = df_all[\"age\"] ** 2 / 100\n",
    "df_all[\"age_group\"] = 1\n",
    "df_all.loc[(df_all[\"age\"] >= 25) & (df_all[\"age\"] < 30), \"age_group\"] = 2\n",
    "df_all.loc[(df_all[\"age\"] >= 30) & (df_all[\"age\"] < 35), \"age_group\"] = 3\n",
    "df_all.loc[(df_all[\"age\"] >= 35) & (df_all[\"age\"] < 40), \"age_group\"] = 4\n",
    "df_all.loc[(df_all[\"age\"] >= 40) & (df_all[\"age\"] < 45), \"age_group\"] = 5\n",
    "df_all.loc[(df_all[\"age\"] >= 45) & (df_all[\"age\"] < 51), \"age_group\"] = 6\n",
    "df_all[\"ageg_2\"] = (df_all[\"age_group\"] == 2).astype(int)\n",
    "df_all[\"ageg_3\"] = (df_all[\"age_group\"] == 3).astype(int)\n",
    "df_all[\"ageg_4\"] = (df_all[\"age_group\"] == 4).astype(int)\n",
    "df_all[\"ageg_5\"] = (df_all[\"age_group\"] == 5).astype(int)\n",
    "df_all[\"ageg_6\"] = (df_all[\"age_group\"] == 6).astype(int)\n",
    "\n",
    "# Year variables\n",
    "df_all[\"year\"] = df_all[\"year\"].astype(int)\n",
    "df_all[\"yeart\"] = df_all[\"year\"] - 1977\n",
    "df_all[\"yeartsq\"] = df_all[\"yeart\"] ** 2 / 100\n",
    "df_all[\"yeartcb\"] = df_all[\"yeart\"] ** 3 / 1000\n",
    "df_all[\"year_group\"] = 1 # Carter Pre-Volker 1977-1979\n",
    "df_all.loc[(df_all[\"year\"] >= 1977) & (df_all[\"year\"] < 1980), \"year_group\"] = 1\n",
    "df_all.loc[(df_all[\"year\"] >= 1980) & (df_all[\"year\"] < 1983), \"year_group\"] = 2 # Volker Recession 1980-1982\n",
    "df_all.loc[(df_all[\"year\"] >= 1983) & (df_all[\"year\"] < 1990), \"year_group\"] = 3 # Reagan Expansion 1983-1989\n",
    "df_all.loc[(df_all[\"year\"] >= 1990) & (df_all[\"year\"] < 1995), \"year_group\"] = 4 # Early 90s Recession + Jobless Recovery 1990-1994\n",
    "df_all.loc[(df_all[\"year\"] >= 1995) & (df_all[\"year\"] < 2001), \"year_group\"] = 5 # Late 90s Boom 1995-2000\n",
    "df_all.loc[(df_all[\"year\"] >= 2001) & (df_all[\"year\"] < 2004), \"year_group\"] = 6 # Dot-com Bust + Early 2000s Recession 2001-2003\n",
    "df_all.loc[(df_all[\"year\"] >= 2004) & (df_all[\"year\"] < 2008), \"year_group\"] = 7 # Housing Boom + Pre-GFC 2004-2007\n",
    "df_all.loc[(df_all[\"year\"] >= 2008) & (df_all[\"year\"] < 2013), \"year_group\"] = 8 # Great Recession and Aftermath 2008-2012\n",
    "df_all[\"yearg_1\"] = (df_all[\"year_group\"] == 1).astype(int)\n",
    "df_all[\"yearg_2\"] = (df_all[\"year_group\"] == 2).astype(int)\n",
    "df_all[\"yearg_3\"] = (df_all[\"year_group\"] == 3).astype(int)\n",
    "df_all[\"yearg_4\"] = (df_all[\"year_group\"] == 4).astype(int)\n",
    "df_all[\"yearg_5\"] = (df_all[\"year_group\"] == 5).astype(int)\n",
    "df_all[\"yearg_6\"] = (df_all[\"year_group\"] == 6).astype(int)\n",
    "df_all[\"yearg_7\"] = (df_all[\"year_group\"] == 7).astype(int)\n",
    "df_all[\"yearg_8\"] = (df_all[\"year_group\"] == 8).astype(int)\n",
    "\n",
    "# State fixed effects (drop one to avoid multicollinearity)\n",
    "state_dummies = pd.get_dummies(df_all[\"stfips\"], prefix=\"state\", drop_first=True).astype(float)\n",
    "df_all = pd.concat([df_all, state_dummies], axis=1)\n",
    "state_cols = sorted(state_dummies.columns)\n",
    "\n",
    "# Year fixed effects (drop one to avoid multicollinearity)\n",
    "year_dummies = pd.get_dummies(df_all[\"year\"], prefix=\"year\", drop_first=True)\n",
    "df_all = pd.concat([df_all, year_dummies], axis=1)\n",
    "year_cols = year_dummies.columns.tolist()\n",
    "\n",
    "# Constants for annualizing hourly wages\n",
    "hours_per_year_pt = 1000\n",
    "hours_per_year_ft = 2000\n",
    "\n",
    "# Winsorize wage at 1st and 99th percentiles and save original wage column\n",
    "wage_p01 = df_all[\"wage\"].quantile(0.01)\n",
    "wage_p99 = df_all[\"wage\"].quantile(0.99)\n",
    "df_all[\"wage_original\"] = df_all[\"wage\"]\n",
    "df_all[\"wage\"] = df_all[\"wage\"].clip(lower=wage_p01, upper=wage_p99)\n",
    "\n",
    "# Create log wages (after winsorization): valid if wage is positive and not missing\n",
    "df_all[\"lnwage\"] = np.where(df_all[\"wage\"].notna() & (df_all[\"wage\"] > 0), np.log(df_all[\"wage\"]), np.nan)\n",
    "df_wageonly = df_all[\n",
    "    df_all[\"wage\"].notna() &\n",
    "    (df_all[\"wage\"] > 0) &\n",
    "    (df_all[\"employed_ptft_robert\"].isin([1, 2]))\n",
    "].copy()\n",
    "df_wageonly[\"lnwage\"] = np.log(df_wageonly[\"wage\"])\n",
    "\n",
    "# Only include part-time or full-time employed individuals for mean wage by year and employment type\n",
    "df_valid_raw = df_all[\n",
    "    df_all[\"employed_ptft_robert\"].isin([1, 2]) & \n",
    "    df_all[\"wage\"].notna() & \n",
    "    (df_all[\"wage\"] > 0)\n",
    "]\n",
    "mean_wage_by_year = df_valid_raw.groupby([\"year\", \"employed_ptft_robert\"])[\"wage\"].mean().unstack()\n",
    "mean_wage_by_year.columns = [\"Part-Time\", \"Full-Time\"]\n",
    "\n",
    "# Employment shares (non-employment, part-time, full-time) computed on full sample\n",
    "employment_shares = df_all.groupby(\"year\")[[\"actual_nonemp\", \"actual_part\", \"actual_full\"]].mean()\n",
    "\n",
    "# ------------------------- Generate actual moments -------------------------------------------------\n",
    "\n",
    "# Create part-time and full-time log wages\n",
    "df_all[\"lnwage_pt_real\"] = np.where(df_all[\"employed_ptft_robert\"] == 1, np.log(df_all[\"wage\"]), np.nan)\n",
    "df_all[\"lnwage_ft_real\"] = np.where(df_all[\"employed_ptft_robert\"] == 2, np.log(df_all[\"wage\"]), np.nan)\n",
    "\n",
    "# Create part-time and full-time samples\n",
    "df_pt = df_all[df_all[\"employed_ptft_robert\"] == 1].copy()\n",
    "df_ft = df_all[df_all[\"employed_ptft_robert\"] == 2].copy()\n",
    "\n",
    "# Regressors for linear probability models with state and year fixed effects\n",
    "X_aux = sm.add_constant(\n",
    "    df_all[[\n",
    "        \"edu_2\", \"edu_3\", \"race_2\", \"race_3\", \"age\", \"agesq\",\n",
    "        \"child_1\", \"child_2\", \"child_3\"\n",
    "    ] + state_cols + year_cols]\n",
    ")\n",
    "\n",
    "# Regressors for accepted log wage regressions with state and year fixed effects (PT)\n",
    "X_pt = sm.add_constant(\n",
    "    df_pt[[\n",
    "        \"edu_2\", \"edu_3\", \"race_2\", \"race_3\", \"age\", \"agesq\"\n",
    "    ] + state_cols + year_cols]\n",
    ")\n",
    "\n",
    "# Regressors for accepted log wage regressions with state and year fixed effects (FT)\n",
    "X_ft = sm.add_constant(\n",
    "    df_ft[[\n",
    "        \"edu_2\", \"edu_3\", \"race_2\", \"race_3\", \"age\", \"agesq\"\n",
    "    ] + state_cols + year_cols]\n",
    ")\n",
    "\n",
    "# Ensure X's are fully numeric\n",
    "X_aux = X_aux.astype(float)\n",
    "X_pt = X_pt.astype(float)\n",
    "X_ft = X_ft.astype(float)\n",
    "\n",
    "# Linear probability auxiliary regression: Employed (PT or FT) vs NE\n",
    "reg_emp = sm.OLS(df_all[\"employed\"], X_aux).fit(cov_type=\"HC1\")\n",
    "se_emp = reg_emp.bse\n",
    "\n",
    "# Linear probability auxiliary regression: PT vs NE â€” mask to only keep NE and PT\n",
    "mask_pt_ne = df_all[\"employed_ptft_robert\"].isin([0, 1])\n",
    "share_employed_pt_ne = df_all.loc[mask_pt_ne, \"employed_pt\"].mean()\n",
    "reg_emp_pt = sm.OLS(df_all.loc[mask_pt_ne, \"employed_pt\"], X_aux.loc[mask_pt_ne]).fit(cov_type=\"HC1\")\n",
    "se_emp_pt = reg_emp_pt.bse\n",
    "\n",
    "# Linear probability auxiliary regression: FT vs NE â€” mask to only keep NE and FT\n",
    "mask_ft_ne = df_all[\"employed_ptft_robert\"].isin([0, 2])\n",
    "share_employed_ft_ne = df_all.loc[mask_ft_ne, \"employed_ft\"].mean()\n",
    "reg_emp_ft = sm.OLS(df_all.loc[mask_ft_ne, \"employed_ft\"], X_aux.loc[mask_ft_ne]).fit(cov_type=\"HC1\")\n",
    "se_emp_ft = reg_emp_ft.bse\n",
    "\n",
    "# Part-time accepted wage auxiliary regression\n",
    "reg_pt = sm.OLS(df_pt[\"lnwage_pt_real\"], X_pt).fit(cov_type=\"HC1\")\n",
    "se_pt = reg_pt.bse\n",
    "resid_pt = df_pt[\"lnwage_pt_real\"] - reg_pt.predict(X_pt)\n",
    "r2_pt = reg_pt.rsquared\n",
    "pred_pt = reg_pt.predict(X_pt)\n",
    "n_pt = len(pred_pt)\n",
    "var_pred_pt = np.var(pred_pt, ddof=1)\n",
    "\n",
    "# Full-time accepted wage auxiliary regression\n",
    "reg_ft = sm.OLS(df_ft[\"lnwage_ft_real\"], X_ft).fit(cov_type=\"HC1\")\n",
    "se_ft = reg_ft.bse\n",
    "resid_ft = df_ft[\"lnwage_ft_real\"] - reg_ft.predict(X_ft)\n",
    "r2_ft = reg_ft.rsquared\n",
    "pred_ft = reg_ft.predict(X_ft)\n",
    "n_ft = len(pred_ft)\n",
    "var_pred_ft = np.var(pred_ft, ddof=1)\n",
    "\n",
    "s1 = df_all[\"actual_nonemp\"].mean()\n",
    "s2 = df_all[\"actual_part\"].mean()\n",
    "\n",
    "s3 = reg_emp_pt.params[\"const\"]\n",
    "s4 = reg_emp_pt.params[\"edu_2\"]\n",
    "s5 = reg_emp_pt.params[\"edu_3\"]\n",
    "s6 = reg_emp_pt.params[\"race_2\"]\n",
    "s7 = reg_emp_pt.params[\"race_3\"]\n",
    "s8 = reg_emp_pt.params[\"age\"]\n",
    "s9 = reg_emp_pt.params[\"agesq\"]\n",
    "s10 = reg_emp_pt.params[\"child_1\"]\n",
    "s11 = reg_emp_pt.params[\"child_2\"]\n",
    "s12 = reg_emp_pt.params[\"child_3\"]\n",
    "\n",
    "s13 = reg_emp_ft.params[\"const\"]\n",
    "s14 = reg_emp_ft.params[\"edu_2\"]\n",
    "s15 = reg_emp_ft.params[\"edu_3\"]\n",
    "s16 = reg_emp_ft.params[\"race_2\"]\n",
    "s17 = reg_emp_ft.params[\"race_3\"]\n",
    "s18 = reg_emp_ft.params[\"age\"]\n",
    "s19 = reg_emp_ft.params[\"agesq\"]\n",
    "s20 = reg_emp_ft.params[\"child_1\"]\n",
    "s21 = reg_emp_ft.params[\"child_2\"]\n",
    "s22 = reg_emp_ft.params[\"child_3\"]\n",
    "\n",
    "s23 = reg_pt.params[\"const\"]\n",
    "s24 = reg_pt.params[\"edu_2\"]\n",
    "s25 = reg_pt.params[\"edu_3\"]\n",
    "s26 = reg_pt.params[\"race_2\"]\n",
    "s27 = reg_pt.params[\"race_3\"]\n",
    "s28 = reg_pt.params[\"age\"]\n",
    "s29 = reg_pt.params[\"agesq\"]\n",
    "s30 = np.var(resid_pt, ddof=1)\n",
    "s31 = r2_pt\n",
    "\n",
    "s32 = reg_ft.params[\"const\"]\n",
    "s33 = reg_ft.params[\"edu_2\"]\n",
    "s34 = reg_ft.params[\"edu_3\"]\n",
    "s35 = reg_ft.params[\"race_2\"]\n",
    "s36 = reg_ft.params[\"race_3\"]\n",
    "s37 = reg_ft.params[\"age\"]\n",
    "s38 = reg_ft.params[\"agesq\"]\n",
    "s39 = np.var(resid_ft, ddof=1)\n",
    "s40 = r2_ft\n",
    "\n",
    "s41 = pred_ft.mean() - pred_pt.mean()\n",
    "\n",
    "s42 = df_pt.loc[df_pt[\"edu\"] == 1, \"lnwage_pt_real\"].mean()\n",
    "s43 = df_pt.loc[df_pt[\"edu\"] == 2, \"lnwage_pt_real\"].mean()\n",
    "s44 = df_pt.loc[df_pt[\"edu\"] == 3, \"lnwage_pt_real\"].mean()\n",
    "s45 = df_pt.loc[df_pt[\"race\"] == 1, \"lnwage_pt_real\"].mean()\n",
    "s46 = df_pt.loc[df_pt[\"race\"] == 2, \"lnwage_pt_real\"].mean()\n",
    "s47 = df_pt.loc[df_pt[\"race\"] == 3, \"lnwage_pt_real\"].mean()\n",
    "s48 = df_pt.loc[df_pt[\"age_group\"] == 1, \"lnwage_pt_real\"].mean()\n",
    "s49 = df_pt.loc[df_pt[\"age_group\"] == 2, \"lnwage_pt_real\"].mean()\n",
    "s50 = df_pt.loc[df_pt[\"age_group\"] == 3, \"lnwage_pt_real\"].mean()\n",
    "s51 = df_pt.loc[df_pt[\"age_group\"] == 4, \"lnwage_pt_real\"].mean()\n",
    "s52 = df_pt.loc[df_pt[\"age_group\"] == 5, \"lnwage_pt_real\"].mean()\n",
    "s53 = df_pt.loc[df_pt[\"age_group\"] == 6, \"lnwage_pt_real\"].mean()\n",
    "s54 = df_pt.loc[df_pt[\"year_group\"] == 1, \"lnwage_pt_real\"].mean()\n",
    "s55 = df_pt.loc[df_pt[\"year_group\"] == 2, \"lnwage_pt_real\"].mean()\n",
    "s56 = df_pt.loc[df_pt[\"year_group\"] == 3, \"lnwage_pt_real\"].mean()\n",
    "s57 = df_pt.loc[df_pt[\"year_group\"] == 4, \"lnwage_pt_real\"].mean()\n",
    "s58 = df_pt.loc[df_pt[\"year_group\"] == 5, \"lnwage_pt_real\"].mean()\n",
    "s59 = df_pt.loc[df_pt[\"year_group\"] == 6, \"lnwage_pt_real\"].mean()\n",
    "s60 = df_pt.loc[df_pt[\"year_group\"] == 7, \"lnwage_pt_real\"].mean()\n",
    "s61 = df_pt.loc[df_pt[\"year_group\"] == 8, \"lnwage_pt_real\"].mean()\n",
    "\n",
    "s62 = df_ft.loc[df_ft[\"edu\"] == 1, \"lnwage_ft_real\"].mean()\n",
    "s63 = df_ft.loc[df_ft[\"edu\"] == 2, \"lnwage_ft_real\"].mean()\n",
    "s64 = df_ft.loc[df_ft[\"edu\"] == 3, \"lnwage_ft_real\"].mean()\n",
    "s65 = df_ft.loc[df_ft[\"race\"] == 1, \"lnwage_ft_real\"].mean()\n",
    "s66 = df_ft.loc[df_ft[\"race\"] == 2, \"lnwage_ft_real\"].mean()\n",
    "s67 = df_ft.loc[df_ft[\"race\"] == 3, \"lnwage_ft_real\"].mean()\n",
    "s68 = df_ft.loc[df_ft[\"age_group\"] == 1, \"lnwage_ft_real\"].mean()\n",
    "s69 = df_ft.loc[df_ft[\"age_group\"] == 2, \"lnwage_ft_real\"].mean()\n",
    "s70 = df_ft.loc[df_ft[\"age_group\"] == 3, \"lnwage_ft_real\"].mean()\n",
    "s71 = df_ft.loc[df_ft[\"age_group\"] == 4, \"lnwage_ft_real\"].mean()\n",
    "s72 = df_ft.loc[df_ft[\"age_group\"] == 5, \"lnwage_ft_real\"].mean()\n",
    "s73 = df_ft.loc[df_ft[\"age_group\"] == 6, \"lnwage_ft_real\"].mean()\n",
    "s74 = df_ft.loc[df_ft[\"year_group\"] == 1, \"lnwage_ft_real\"].mean()\n",
    "s75 = df_ft.loc[df_ft[\"year_group\"] == 2, \"lnwage_ft_real\"].mean()\n",
    "s76 = df_ft.loc[df_ft[\"year_group\"] == 3, \"lnwage_ft_real\"].mean()\n",
    "s77 = df_ft.loc[df_ft[\"year_group\"] == 4, \"lnwage_ft_real\"].mean()\n",
    "s78 = df_ft.loc[df_ft[\"year_group\"] == 5, \"lnwage_ft_real\"].mean()\n",
    "s79 = df_ft.loc[df_ft[\"year_group\"] == 6, \"lnwage_ft_real\"].mean()\n",
    "s80 = df_ft.loc[df_ft[\"year_group\"] == 7, \"lnwage_ft_real\"].mean()\n",
    "s81 = df_ft.loc[df_ft[\"year_group\"] == 8, \"lnwage_ft_real\"].mean()\n",
    "\n",
    "s82 = df_all.loc[mask_pt_ne & (df_all[\"edu\"] == 1), \"employed_pt\"].mean()\n",
    "s83 = df_all.loc[mask_pt_ne & (df_all[\"edu\"] == 2), \"employed_pt\"].mean()\n",
    "s84 = df_all.loc[mask_pt_ne & (df_all[\"edu\"] == 3), \"employed_pt\"].mean()\n",
    "s85 = df_all.loc[mask_pt_ne & (df_all[\"race\"] == 1), \"employed_pt\"].mean()\n",
    "s86 = df_all.loc[mask_pt_ne & (df_all[\"race\"] == 2), \"employed_pt\"].mean()\n",
    "s87 = df_all.loc[mask_pt_ne & (df_all[\"race\"] == 3), \"employed_pt\"].mean()\n",
    "s88 = df_all.loc[mask_pt_ne & (df_all[\"age_group\"] == 1), \"employed_pt\"].mean()\n",
    "s89 = df_all.loc[mask_pt_ne & (df_all[\"age_group\"] == 2), \"employed_pt\"].mean()\n",
    "s90 = df_all.loc[mask_pt_ne & (df_all[\"age_group\"] == 3), \"employed_pt\"].mean()\n",
    "s91 = df_all.loc[mask_pt_ne & (df_all[\"age_group\"] == 4), \"employed_pt\"].mean()\n",
    "s92 = df_all.loc[mask_pt_ne & (df_all[\"age_group\"] == 5), \"employed_pt\"].mean()\n",
    "s93 = df_all.loc[mask_pt_ne & (df_all[\"age_group\"] == 6), \"employed_pt\"].mean()\n",
    "s94 = df_all.loc[mask_pt_ne & (df_all[\"year_group\"] == 1), \"employed_pt\"].mean()\n",
    "s95 = df_all.loc[mask_pt_ne & (df_all[\"year_group\"] == 2), \"employed_pt\"].mean()\n",
    "s96 = df_all.loc[mask_pt_ne & (df_all[\"year_group\"] == 3), \"employed_pt\"].mean()\n",
    "s97 = df_all.loc[mask_pt_ne & (df_all[\"year_group\"] == 4), \"employed_pt\"].mean()\n",
    "s98 = df_all.loc[mask_pt_ne & (df_all[\"year_group\"] == 5), \"employed_pt\"].mean()\n",
    "s99 = df_all.loc[mask_pt_ne & (df_all[\"year_group\"] == 6), \"employed_pt\"].mean()\n",
    "s100 = df_all.loc[mask_pt_ne & (df_all[\"year_group\"] == 7), \"employed_pt\"].mean()\n",
    "s101 = df_all.loc[mask_pt_ne & (df_all[\"year_group\"] == 8), \"employed_pt\"].mean()\n",
    "s102 = df_all.loc[mask_pt_ne & (df_all[\"child_1\"] == 1), \"employed_pt\"].mean()\n",
    "s103 = df_all.loc[mask_pt_ne & (df_all[\"child_2\"] == 1), \"employed_pt\"].mean()\n",
    "s104 = df_all.loc[mask_pt_ne & (df_all[\"child_3\"] == 1), \"employed_pt\"].mean()\n",
    "\n",
    "s105 = df_all.loc[mask_ft_ne & (df_all[\"edu\"] == 1), \"employed_ft\"].mean()\n",
    "s106 = df_all.loc[mask_ft_ne & (df_all[\"edu\"] == 2), \"employed_ft\"].mean()\n",
    "s107 = df_all.loc[mask_ft_ne & (df_all[\"edu\"] == 3), \"employed_ft\"].mean()\n",
    "s108 = df_all.loc[mask_ft_ne & (df_all[\"race\"] == 1), \"employed_ft\"].mean()\n",
    "s109 = df_all.loc[mask_ft_ne & (df_all[\"race\"] == 2), \"employed_ft\"].mean()\n",
    "s110 = df_all.loc[mask_ft_ne & (df_all[\"race\"] == 3), \"employed_ft\"].mean()\n",
    "s111 = df_all.loc[mask_ft_ne & (df_all[\"age_group\"] == 1), \"employed_ft\"].mean()\n",
    "s112 = df_all.loc[mask_ft_ne & (df_all[\"age_group\"] == 2), \"employed_ft\"].mean()\n",
    "s113 = df_all.loc[mask_ft_ne & (df_all[\"age_group\"] == 3), \"employed_ft\"].mean()\n",
    "s114 = df_all.loc[mask_ft_ne & (df_all[\"age_group\"] == 4), \"employed_ft\"].mean()\n",
    "s115 = df_all.loc[mask_ft_ne & (df_all[\"age_group\"] == 5), \"employed_ft\"].mean()\n",
    "s116 = df_all.loc[mask_ft_ne & (df_all[\"age_group\"] == 6), \"employed_ft\"].mean()\n",
    "s117 = df_all.loc[mask_ft_ne & (df_all[\"year_group\"] == 1), \"employed_ft\"].mean()\n",
    "s118 = df_all.loc[mask_ft_ne & (df_all[\"year_group\"] == 2), \"employed_ft\"].mean()\n",
    "s119 = df_all.loc[mask_ft_ne & (df_all[\"year_group\"] == 3), \"employed_ft\"].mean()\n",
    "s120 = df_all.loc[mask_ft_ne & (df_all[\"year_group\"] == 4), \"employed_ft\"].mean()\n",
    "s121 = df_all.loc[mask_ft_ne & (df_all[\"year_group\"] == 5), \"employed_ft\"].mean()\n",
    "s122 = df_all.loc[mask_ft_ne & (df_all[\"year_group\"] == 6), \"employed_ft\"].mean()\n",
    "s123 = df_all.loc[mask_ft_ne & (df_all[\"year_group\"] == 7), \"employed_ft\"].mean()\n",
    "s124 = df_all.loc[mask_ft_ne & (df_all[\"year_group\"] == 8), \"employed_ft\"].mean()\n",
    "s125 = df_all.loc[mask_ft_ne & (df_all[\"child_1\"] == 1), \"employed_ft\"].mean()\n",
    "s126 = df_all.loc[mask_ft_ne & (df_all[\"child_2\"] == 1), \"employed_ft\"].mean()\n",
    "s127 = df_all.loc[mask_ft_ne & (df_all[\"child_3\"] == 1), \"employed_ft\"].mean()\n",
    "\n",
    "# Define number of moments globally\n",
    "num_moments = 127\n",
    "\n",
    "# Weights using estimated robust variances for regression-based moments\n",
    "weights = {\n",
    "    3: 1 / se_emp_pt[\"const\"]**2,\n",
    "    4: 1 / se_emp_pt[\"edu_2\"]**2,\n",
    "    5: 1 / se_emp_pt[\"edu_3\"]**2,\n",
    "    6: 1 / se_emp_pt[\"race_2\"]**2,\n",
    "    7: 1 / se_emp_pt[\"race_3\"]**2,\n",
    "    8: 1 / se_emp_pt[\"age\"]**2,\n",
    "    9: 1 / se_emp_pt[\"agesq\"]**2,\n",
    "    10: 1 / se_emp_pt[\"child_1\"]**2,\n",
    "    11: 1 / se_emp_pt[\"child_2\"]**2,\n",
    "    12: 1 / se_emp_pt[\"child_3\"]**2,\n",
    "\n",
    "    13: 1 / se_emp_ft[\"const\"]**2,\n",
    "    14: 1 / se_emp_ft[\"edu_2\"]**2,\n",
    "    15: 1 / se_emp_ft[\"edu_3\"]**2,\n",
    "    16: 1 / se_emp_ft[\"race_2\"]**2,\n",
    "    17: 1 / se_emp_ft[\"race_3\"]**2,\n",
    "    18: 1 / se_emp_ft[\"age\"]**2,\n",
    "    19: 1 / se_emp_ft[\"agesq\"]**2,\n",
    "    20: 1 / se_emp_ft[\"child_1\"]**2,\n",
    "    21: 1 / se_emp_ft[\"child_2\"]**2,\n",
    "    22: 1 / se_emp_ft[\"child_3\"]**2,\n",
    "\n",
    "    23: 1 / se_pt[\"const\"]**2,\n",
    "    24: 1 / se_pt[\"edu_2\"]**2,\n",
    "    25: 1 / se_pt[\"edu_3\"]**2,\n",
    "    26: 1 / se_pt[\"race_2\"]**2,\n",
    "    27: 1 / se_pt[\"race_3\"]**2,\n",
    "    28: 1 / se_pt[\"age\"]**2,\n",
    "    29: 1 / se_pt[\"agesq\"]**2,\n",
    "\n",
    "    32: 1 / se_ft[\"const\"]**2,\n",
    "    33: 1 / se_ft[\"edu_2\"]**2,\n",
    "    34: 1 / se_ft[\"edu_3\"]**2,\n",
    "    35: 1 / se_ft[\"race_2\"]**2,\n",
    "    36: 1 / se_ft[\"race_3\"]**2,\n",
    "    37: 1 / se_ft[\"age\"]**2,\n",
    "    38: 1 / se_ft[\"agesq\"]**2\n",
    "}\n",
    "\n",
    "# Weights using empirical variances for non-regression based moments\n",
    "weights[1] = 1 / (np.var(df_all[\"actual_nonemp\"], ddof=1) / len(df_all))\n",
    "weights[2] = 1 / (np.var(df_all[\"actual_part\"], ddof=1) / len(df_all))\n",
    "\n",
    "\n",
    "weights[30] = 1 / (2 * np.var(resid_pt, ddof=1)**2 / (len(resid_pt) - X_pt.shape[1]))\n",
    "weights[31] = 1 / (4 * r2_pt * (1 - r2_pt)**2 / len(df_pt))\n",
    "\n",
    "weights[39] = 1 / (2 * np.var(resid_ft, ddof=1)**2 / (len(resid_ft) - X_ft.shape[1]))\n",
    "weights[40] = 1 / (4 * r2_ft * (1 - r2_ft)**2 / len(df_ft))\n",
    "\n",
    "weights[41] = 1 / ((var_pred_ft / n_ft) + (var_pred_pt / n_pt))\n",
    "\n",
    "weights[42] = 1 / np.var(df_pt.loc[df_pt[\"edu\"] == 1, \"lnwage_pt_real\"])\n",
    "weights[43] = 1 / np.var(df_pt.loc[df_pt[\"edu\"] == 2, \"lnwage_pt_real\"])\n",
    "weights[44] = 1 / np.var(df_pt.loc[df_pt[\"edu\"] == 3, \"lnwage_pt_real\"])\n",
    "weights[45] = 1 / np.var(df_pt.loc[df_pt[\"race\"] == 1, \"lnwage_pt_real\"])\n",
    "weights[46] = 1 / np.var(df_pt.loc[df_pt[\"race\"] == 2, \"lnwage_pt_real\"])\n",
    "weights[47] = 1 / np.var(df_pt.loc[df_pt[\"race\"] == 3, \"lnwage_pt_real\"])\n",
    "weights[48] = 1 / np.var(df_pt.loc[df_pt[\"age_group\"] == 1, \"lnwage_pt_real\"])\n",
    "weights[49] = 1 / np.var(df_pt.loc[df_pt[\"age_group\"] == 2, \"lnwage_pt_real\"])\n",
    "weights[50] = 1 / np.var(df_pt.loc[df_pt[\"age_group\"] == 3, \"lnwage_pt_real\"])\n",
    "weights[51] = 1 / np.var(df_pt.loc[df_pt[\"age_group\"] == 4, \"lnwage_pt_real\"])\n",
    "weights[52] = 1 / np.var(df_pt.loc[df_pt[\"age_group\"] == 5, \"lnwage_pt_real\"])\n",
    "weights[53] = 1 / np.var(df_pt.loc[df_pt[\"age_group\"] == 6, \"lnwage_pt_real\"])\n",
    "weights[54] = 1 / np.var(df_pt.loc[df_pt[\"year_group\"] == 1, \"lnwage_pt_real\"])\n",
    "weights[55] = 1 / np.var(df_pt.loc[df_pt[\"year_group\"] == 2, \"lnwage_pt_real\"])\n",
    "weights[56] = 1 / np.var(df_pt.loc[df_pt[\"year_group\"] == 3, \"lnwage_pt_real\"])\n",
    "weights[57] = 1 / np.var(df_pt.loc[df_pt[\"year_group\"] == 4, \"lnwage_pt_real\"])\n",
    "weights[58] = 1 / np.var(df_pt.loc[df_pt[\"year_group\"] == 5, \"lnwage_pt_real\"])\n",
    "weights[59] = 1 / np.var(df_pt.loc[df_pt[\"year_group\"] == 6, \"lnwage_pt_real\"])\n",
    "weights[60] = 1 / np.var(df_pt.loc[df_pt[\"year_group\"] == 7, \"lnwage_pt_real\"])\n",
    "weights[61] = 1 / np.var(df_pt.loc[df_pt[\"year_group\"] == 8, \"lnwage_pt_real\"])\n",
    "\n",
    "weights[62] = 1 / np.var(df_ft.loc[df_ft[\"edu\"] == 1, \"lnwage_ft_real\"])\n",
    "weights[63] = 1 / np.var(df_ft.loc[df_ft[\"edu\"] == 2, \"lnwage_ft_real\"])\n",
    "weights[64] = 1 / np.var(df_ft.loc[df_ft[\"edu\"] == 3, \"lnwage_ft_real\"])\n",
    "weights[65] = 1 / np.var(df_ft.loc[df_ft[\"race\"] == 1, \"lnwage_ft_real\"])\n",
    "weights[66] = 1 / np.var(df_ft.loc[df_ft[\"race\"] == 2, \"lnwage_ft_real\"])\n",
    "weights[67] = 1 / np.var(df_ft.loc[df_ft[\"race\"] == 3, \"lnwage_ft_real\"])\n",
    "weights[68] = 1 / np.var(df_ft.loc[df_ft[\"age_group\"] == 1, \"lnwage_ft_real\"])\n",
    "weights[69] = 1 / np.var(df_ft.loc[df_ft[\"age_group\"] == 2, \"lnwage_ft_real\"])\n",
    "weights[70] = 1 / np.var(df_ft.loc[df_ft[\"age_group\"] == 3, \"lnwage_ft_real\"])\n",
    "weights[71] = 1 / np.var(df_ft.loc[df_ft[\"age_group\"] == 4, \"lnwage_ft_real\"])\n",
    "weights[72] = 1 / np.var(df_ft.loc[df_ft[\"age_group\"] == 5, \"lnwage_ft_real\"])\n",
    "weights[73] = 1 / np.var(df_ft.loc[df_ft[\"age_group\"] == 6, \"lnwage_ft_real\"])\n",
    "weights[74] = 1 / np.var(df_ft.loc[df_ft[\"year_group\"] == 1, \"lnwage_ft_real\"])\n",
    "weights[75] = 1 / np.var(df_ft.loc[df_ft[\"year_group\"] == 2, \"lnwage_ft_real\"])\n",
    "weights[76] = 1 / np.var(df_ft.loc[df_ft[\"year_group\"] == 3, \"lnwage_ft_real\"])\n",
    "weights[77] = 1 / np.var(df_ft.loc[df_ft[\"year_group\"] == 4, \"lnwage_ft_real\"])\n",
    "weights[78] = 1 / np.var(df_ft.loc[df_ft[\"year_group\"] == 5, \"lnwage_ft_real\"])\n",
    "weights[79] = 1 / np.var(df_ft.loc[df_ft[\"year_group\"] == 6, \"lnwage_ft_real\"])\n",
    "weights[80] = 1 / np.var(df_ft.loc[df_ft[\"year_group\"] == 7, \"lnwage_ft_real\"])\n",
    "weights[81] = 1 / np.var(df_ft.loc[df_ft[\"year_group\"] == 8, \"lnwage_ft_real\"])\n",
    "\n",
    "weights[82] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"edu\"] == 1)].shape[0])\n",
    "weights[83] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"edu\"] == 2)].shape[0])\n",
    "weights[84] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"edu\"] == 3)].shape[0])\n",
    "weights[85] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"race\"] == 1)].shape[0])\n",
    "weights[86] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"race\"] == 2)].shape[0])\n",
    "weights[87] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"race\"] == 3)].shape[0])\n",
    "weights[88] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"age_group\"] == 1)].shape[0])\n",
    "weights[89] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"age_group\"] == 2)].shape[0])\n",
    "weights[90] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"age_group\"] == 3)].shape[0])\n",
    "weights[91] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"age_group\"] == 4)].shape[0])\n",
    "weights[92] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"age_group\"] == 5)].shape[0])\n",
    "weights[93] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"age_group\"] == 6)].shape[0])\n",
    "weights[94] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"year_group\"] == 1)].shape[0])\n",
    "weights[95] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"year_group\"] == 2)].shape[0])\n",
    "weights[96] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"year_group\"] == 3)].shape[0])\n",
    "weights[97] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"year_group\"] == 4)].shape[0])\n",
    "weights[98] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"year_group\"] == 5)].shape[0])\n",
    "weights[99] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"year_group\"] == 6)].shape[0])\n",
    "weights[100] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"year_group\"] == 7)].shape[0])\n",
    "weights[101] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"year_group\"] == 8)].shape[0])\n",
    "weights[102] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"child_1\"] == 1)].shape[0])\n",
    "weights[103] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"child_2\"] == 1)].shape[0])\n",
    "weights[104] = 1 / (share_employed_pt_ne * (1 - share_employed_pt_ne) / df_all[(mask_pt_ne) & (df_all[\"child_3\"] == 1)].shape[0])\n",
    "\n",
    "weights[105] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"edu\"] == 1)].shape[0])\n",
    "weights[106] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"edu\"] == 2)].shape[0])\n",
    "weights[107] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"edu\"] == 3)].shape[0])\n",
    "weights[108] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"race\"] == 1)].shape[0])\n",
    "weights[109] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"race\"] == 2)].shape[0])\n",
    "weights[110] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"race\"] == 3)].shape[0])\n",
    "weights[111] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"age_group\"] == 1)].shape[0])\n",
    "weights[112] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"age_group\"] == 2)].shape[0])\n",
    "weights[113] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"age_group\"] == 3)].shape[0])\n",
    "weights[114] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"age_group\"] == 4)].shape[0])\n",
    "weights[115] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"age_group\"] == 5)].shape[0])\n",
    "weights[116] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"age_group\"] == 6)].shape[0])\n",
    "weights[117] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"year_group\"] == 1)].shape[0])\n",
    "weights[118] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"year_group\"] == 2)].shape[0])\n",
    "weights[119] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"year_group\"] == 3)].shape[0])\n",
    "weights[120] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"year_group\"] == 4)].shape[0])\n",
    "weights[121] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"year_group\"] == 5)].shape[0])\n",
    "weights[122] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"year_group\"] == 6)].shape[0])\n",
    "weights[123] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"year_group\"] == 7)].shape[0])\n",
    "weights[124] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"year_group\"] == 8)].shape[0])\n",
    "weights[125] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"child_1\"] == 1)].shape[0])\n",
    "weights[126] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"child_2\"] == 1)].shape[0])\n",
    "weights[127] = 1 / (share_employed_ft_ne * (1 - share_employed_ft_ne) / df_all[(mask_ft_ne) & (df_all[\"child_3\"] == 1)].shape[0])\n",
    "\n",
    "# Construct base, mean-normalized and log-normalized inverse variance weighting vectors\n",
    "W_base = np.array([weights.get(i, 1.0) for i in range(1, num_moments + 1)])              # base weight vector\n",
    "W_mean_normalized = W_base / np.mean(W_base)                                             # normalize so the mean weight is 1.0\n",
    "W_log_normalized = np.exp(np.log(W_base) - np.mean(np.log(W_base)))                      # log-normalized weights\n",
    "\n",
    "W_manual_scaled = np.ones(num_moments)                                                   # Manual scaling for weighting vector\n",
    "W_manual_scaled[3:9] = 0.0                                                               # all ones except s4-s9 set to 0.0\n",
    "W_manual_scaled[13:19] = 0.0                                                             # and s14-s19 set to 0.0\n",
    "\n",
    "moment_definitions = [\n",
    "    (f\"s{i}: {desc}\", eval(f\"s{i}\"), f\"m{i}\")\n",
    "    for i, desc in enumerate([\n",
    "        \"Proportion in NE\",\n",
    "        \"Proportion in PT\",\n",
    "        \"Probability in PT vs NE constant\",\n",
    "        \"Probability in PT vs NE edu2\",\n",
    "        \"Probability in PT vs NE edu3\",\n",
    "        \"Probability in PT vs NE race2\",\n",
    "        \"Probability in PT vs NE race3\",\n",
    "        \"Probability in PT vs NE age\",\n",
    "        \"Probability in PT vs NE agesq\",\n",
    "        \"Probability in PT vs NE child1\",\n",
    "        \"Probability in PT vs NE child2\",\n",
    "        \"Probability in PT vs NE child3\",\n",
    "        \"Probability in FT vs NE constant\",\n",
    "        \"Probability in FT vs NE edu2\",\n",
    "        \"Probability in FT vs NE edu3\",\n",
    "        \"Probability in FT vs NE race2\",\n",
    "        \"Probability in FT vs NE race3\",\n",
    "        \"Probability in FT vs NE age\",\n",
    "        \"Probability in FT vs NE agesq\",\n",
    "        \"Probability in FT vs NE child1\",\n",
    "        \"Probability in FT vs NE child2\",\n",
    "        \"Probability in FT vs NE child3\",\n",
    "        \"OLS PT lnwage regression constant\",\n",
    "        \"OLS PT lnwage regression edu2\",\n",
    "        \"OLS PT lnwage regression edu3\",\n",
    "        \"OLS PT lnwage regression race2\",\n",
    "        \"OLS PT lnwage regression race3\",\n",
    "        \"OLS PT lnwage regression age\",\n",
    "        \"OLS PT lnwage regression agesq\",\n",
    "        \"OLS PT lnwage regression variance\",\n",
    "        \"RÂ² of PT lnwage regression\",\n",
    "        \"OLS FT lnwage regression constant\",\n",
    "        \"OLS FT lnwage regression edu2\",\n",
    "        \"OLS FT lnwage regression edu3\",\n",
    "        \"OLS FT lnwage regression race2\",\n",
    "        \"OLS FT lnwage regression race3\",\n",
    "        \"OLS FT lnwage regression age\",\n",
    "        \"OLS FT lnwage regression agesq\",\n",
    "        \"OLS FT lnwage regression variance\",\n",
    "        \"RÂ² of FT lnwage regression\",\n",
    "        \"Mean predicted wage gap (FT - PT)\",\n",
    "        \"Mean PT lnwage edu=1\",\n",
    "        \"Mean PT lnwage edu=2\",\n",
    "        \"Mean PT lnwage edu=3\",\n",
    "        \"Mean PT lnwage race=1\",\n",
    "        \"Mean PT lnwage race=2\",\n",
    "        \"Mean PT lnwage race=3\",\n",
    "        \"Mean PT lnwage age 20â€“24\",\n",
    "        \"Mean PT lnwage age 25â€“20\",\n",
    "        \"Mean PT lnwage age 30â€“34\",\n",
    "        \"Mean PT lnwage age 35â€“39\",\n",
    "        \"Mean PT lnwage age 40â€“44\",\n",
    "        \"Mean PT lnwage age 45â€“50\",\n",
    "        \"Mean PT lnwage 1977â€“1979\",\n",
    "        \"Mean PT lnwage 1980â€“1982\",\n",
    "        \"Mean PT lnwage 1983â€“1989\",\n",
    "        \"Mean PT lnwage 1990â€“1994\",\n",
    "        \"Mean PT lnwage 1995â€“2000\",\n",
    "        \"Mean PT lnwage 2001â€“2003\",\n",
    "        \"Mean PT lnwage 2004â€“2007\",\n",
    "        \"Mean PT lnwage 2008â€“2012\",\n",
    "        \"Mean FT lnwage edu=1\",\n",
    "        \"Mean FT lnwage edu=2\",\n",
    "        \"Mean FT lnwage edu=3\",\n",
    "        \"Mean FT lnwage race=1\",\n",
    "        \"Mean FT lnwage race=2\",\n",
    "        \"Mean FT lnwage race=3\",\n",
    "        \"Mean FT lnwage age 20â€“24\",\n",
    "        \"Mean FT lnwage age 25â€“29\",\n",
    "        \"Mean FT lnwage age 30â€“34\",\n",
    "        \"Mean FT lnwage age 35â€“39\",\n",
    "        \"Mean FT lnwage age 40â€“44\",\n",
    "        \"Mean FT lnwage age 45â€“50\",\n",
    "        \"Mean FT lnwage 1977â€“1979\",\n",
    "        \"Mean FT lnwage 1980â€“1982\",\n",
    "        \"Mean FT lnwage 1983â€“1989\",\n",
    "        \"Mean FT lnwage 1990â€“1994\",\n",
    "        \"Mean FT lnwage 1995â€“2000\",\n",
    "        \"Mean FT lnwage 2001â€“2003\",\n",
    "        \"Mean FT lnwage 2004â€“2007\",\n",
    "        \"Mean FT lnwage 2008â€“2012\",\n",
    "        \"Share PT|NE+PT, edu1\",\n",
    "        \"Share PT|NE+PT, edu2\",\n",
    "        \"Share PT|NE+PT, edu3\",\n",
    "        \"Share PT|NE+PT, race1\",\n",
    "        \"Share PT|NE+PT, race2\",\n",
    "        \"Share PT|NE+PT, race3\",\n",
    "        \"Share PT|NE+PT, age 20â€“24\",\n",
    "        \"Share PT|NE+PT, age 25â€“29\",\n",
    "        \"Share PT|NE+PT, age 30â€“34\",\n",
    "        \"Share PT|NE+PT, age 35â€“39\",\n",
    "        \"Share PT|NE+PT, age 40â€“44\",\n",
    "        \"Share PT|NE+PT, age 45â€“50\",\n",
    "        \"Share PT|NE+PT, year 1977â€“1979\",\n",
    "        \"Share PT|NE+PT, year 1980â€“1982\",\n",
    "        \"Share PT|NE+PT, year 1983â€“1989\",\n",
    "        \"Share PT|NE+PT, year 1990â€“1994\",\n",
    "        \"Share PT|NE+PT, year 1995â€“2000\",\n",
    "        \"Share PT|NE+PT, year 2001â€“2003\",\n",
    "        \"Share PT|NE+PT, year 2004â€“2007\",\n",
    "        \"Share PT|NE+PT, year 2008â€“2012\",\n",
    "        \"Share PT|NE+PT, child_1\",\n",
    "        \"Share PT|NE+PT, child_2\",\n",
    "        \"Share PT|NE+PT, child_3\",\n",
    "        \"Share FT|NE+FT, edu1\",\n",
    "        \"Share FT|NE+FT, edu2\",\n",
    "        \"Share FT|NE+FT, edu3\",\n",
    "        \"Share FT|NE+FT, race1\",\n",
    "        \"Share FT|NE+FT, race2\",\n",
    "        \"Share FT|NE+FT, race3\",\n",
    "        \"Share FT|NE+FT, age 20â€“24\",\n",
    "        \"Share FT|NE+FT, age 25â€“29\",\n",
    "        \"Share FT|NE+FT, age 30â€“34\",\n",
    "        \"Share FT|NE+FT, age 35â€“39\",\n",
    "        \"Share FT|NE+FT, age 40â€“44\",\n",
    "        \"Share FT|NE+FT, age 45â€“50\",\n",
    "        \"Share FT|NE+FT, year 1977â€“1979\",\n",
    "        \"Share FT|NE+FT, year 1980â€“1982\",\n",
    "        \"Share FT|NE+FT, year 1983â€“1989\",\n",
    "        \"Share FT|NE+FT, year 1990â€“1994\",\n",
    "        \"Share FT|NE+FT, year 1995â€“2000\",\n",
    "        \"Share FT|NE+FT, year 2001â€“2003\",\n",
    "        \"Share FT|NE+FT, year 2004â€“2007\",\n",
    "        \"Share FT|NE+FT, year 2008â€“2012\",\n",
    "        \"Share FT|NE+FT, child_1\",\n",
    "        \"Share FT|NE+FT, child_2\",\n",
    "        \"Share FT|NE+FT, child_3\"\n",
    "    ], start=1)\n",
    "]\n",
    "\n",
    "# ------------------------- Tax Calculations---------------------------------------------------------\n",
    "\n",
    "# Load federal tax brackets once from full historical file and compute federal tax liability\n",
    "with open(\"/Users/robertsauer/Downloads/Keane/Python/federal_tax_brackets_by_year.json\", \"r\") as f:\n",
    "    FEDERAL_BRACKETS = json.load(f)\n",
    "# Load state tax rates once from full historical file and compute state tax liability\n",
    "with open(\"/Users/robertsauer/Downloads/Keane/Python/state_tax_rates_by_year.json\", \"r\") as f:\n",
    "    STATE_TAX_RATES = json.load(f)\n",
    "# Load social security rate, social security cap and Medicare rate\n",
    "with open(\"/Users/robertsauer/Downloads/Keane/Python/fica_rates_by_year.json\", \"r\") as f:\n",
    "    FICA_RATES = json.load(f)\n",
    "# Load EITC schedules\n",
    "with open(\"/Users/robertsauer/Downloads/Keane/Python/eitc_schedules_by_year.json\", \"r\") as f:\n",
    "    EITC_SCHEDULES = json.load(f)\n",
    "\n",
    "def calculate_federal_tax_vectorized(wages, year, filing_status):\n",
    "    brackets = FEDERAL_BRACKETS.get(str(year), {}).get(filing_status, [])\n",
    "    if not brackets:\n",
    "        return np.zeros_like(wages)\n",
    "    tax = np.zeros_like(wages, dtype=float)\n",
    "    for lower, upper, rate in brackets:\n",
    "        if upper == \"Infinity\":\n",
    "            upper = float(\"inf\")\n",
    "        taxable = np.clip(wages, lower, upper) - lower\n",
    "        taxable = np.where(wages > lower, taxable, 0)\n",
    "        tax += taxable * rate\n",
    "    return tax\n",
    "\n",
    "def calculate_state_tax_vectorized(wages, year, statefips_array):\n",
    "    year_str = str(year)\n",
    "    tax_rates_for_year = STATE_TAX_RATES.get(year_str, {})\n",
    "    rates = np.array([tax_rates_for_year.get(str(sf), 0.0) for sf in statefips_array])\n",
    "    return wages * rates\n",
    "\n",
    "def calculate_fica_tax_vectorized(wages, year):\n",
    "    params = FICA_RATES.get(str(year), {})\n",
    "    ss_rate = params.get(\"ss_rate\", 0.0)\n",
    "    ss_cap = params.get(\"ss_cap\", float(\"inf\"))\n",
    "    medicare_rate = params.get(\"medicare_rate\", 0.0)\n",
    "    wages = np.asarray(wages)\n",
    "    ss_tax = np.minimum(wages, ss_cap) * ss_rate\n",
    "    medicare_tax = wages * medicare_rate\n",
    "    return ss_tax + medicare_tax\n",
    "\n",
    "def calculate_eitc_vectorized(wages, year, filing_status, num_children):\n",
    "    # Cap number of children at 3 as per IRS definition\n",
    "    year_str = str(year)\n",
    "    filing_status_str = str(filing_status)\n",
    "    children_keys = np.clip(num_children, 0, 3).astype(str)\n",
    "\n",
    "    eitc_values = np.zeros_like(wages)\n",
    "\n",
    "    for i in range(len(wages)):\n",
    "        schedule = EITC_SCHEDULES.get(year_str, {}).get(filing_status_str, {}).get(children_keys[i])\n",
    "        if not schedule:\n",
    "            print(\n",
    "                f\"[DEBUG] Missing schedule for year={year_str}, \"\n",
    "                f\"status={filing_status_str}, children={children_keys[i]}\"\n",
    "            )\n",
    "            continue\n",
    "        try:\n",
    "            rate = schedule[\"rate\"]\n",
    "            max_credit = schedule[\"max_credit\"]\n",
    "            phase_out_start = schedule[\"phase_out_start\"]\n",
    "            phase_out_end = schedule[\"phase_out_end\"]\n",
    "        except KeyError as e:\n",
    "            print(\n",
    "                f\"[DEBUG] Missing or invalid schedule for year={year_str}, \"\n",
    "                f\"status={filing_status_str}, children={children_keys[i]}: {e}\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # âœ… Skip invalid cases with zero rate to avoid division by zero\n",
    "        if rate == 0:\n",
    "            print(\n",
    "                f\"[DEBUG] Zero EITC rate for year={year_str}, \"\n",
    "                f\"status={filing_status_str}, children={children_keys[i]}\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        income = wages[i]\n",
    "        if income <= max_credit / rate:\n",
    "            credit = rate * income\n",
    "        elif income <= phase_out_end:\n",
    "            credit = max_credit - rate * (income - phase_out_start)\n",
    "        else:\n",
    "            credit = 0.0\n",
    "\n",
    "        eitc_values[i] = credit\n",
    "\n",
    "    return eitc_values\n",
    "\n",
    "# ------------------------- Fixed Random Draws for Wages and Utility Shocks -------------------------\n",
    "\n",
    "np.random.seed(42)\n",
    "n = len(df_all)\n",
    "eta_1 = np.random.normal(0, 1, n)\n",
    "eta_2 = np.random.normal(0, 1, n)\n",
    "eta_3 = np.random.normal(0, 1, n)\n",
    "eta_4 = np.random.normal(0, 1, n)\n",
    "\n",
    "# ------------------------- Toggles for Simulation/Estimation/Weighting/Standard Errors -------------\n",
    "\n",
    "SKIP_ESTIMATION = False               # Set to True to simulate only\n",
    "\n",
    "USE_WEIGHTED_SMM = False              # Set to False for unweighted SMM\n",
    "USE_LOG_NORMALIZED_WEIGHTS = False    # Set to True to use log normalized weighting in SMM\n",
    "USE_MANUAL_SCALED_WEIGHTS = False     # Set to True to use manual scaling for selected moments\n",
    "\n",
    "assert not (USE_LOG_NORMALIZED_WEIGHTS and USE_MANUAL_SCALED_WEIGHTS), \\\n",
    "    \"Cannot use both log-normalized and manual-scaled weights at the same time. Choose one.\"\n",
    "\n",
    "if not USE_WEIGHTED_SMM:\n",
    "    W = np.ones(num_moments)         # Equal 1.0 weight for all moments in SMM\n",
    "elif USE_MANUAL_SCALED_WEIGHTS:\n",
    "    W = W_manual_scaled              # Manually scaled weights\n",
    "elif USE_LOG_NORMALIZED_WEIGHTS:\n",
    "    W = W_log_normalized             # Log normalized weights in SMM\n",
    "else:\n",
    "    W = W_mean_normalized            # Mean normalized weights in SMM\n",
    "\n",
    "RUN_DELTA = True                     # Set to False to disable Delta Method for standard errors\n",
    "RUN_BOOTSTRAP = False                # Set to True to activate Bootstrap Method for standard errors\n",
    "\n",
    "# ------------------------- Simulate Model ----------------------------------------------------------\n",
    "\n",
    "# Parameters to be estimated\n",
    "param_names = [\n",
    "    \"alpha_ft\",\n",
    "    \"gamma_age_ft\",\n",
    "    \"gamma_agesq_ft\"\n",
    "]\n",
    "\n",
    "# Initial values for parameters\n",
    "theta0 = [\n",
    "    1.152005,\n",
    "    -0.004648,\n",
    "    0.008459\n",
    "]\n",
    "\n",
    "# Custom bump settings for Nelder-Mead simplex\n",
    "custom_bump_percent = 0.25  # % bump for non-zero params 0.10 = 10% (default is 0.05)\n",
    "bump_if_zero = 0.50         # Absolute bump for zero-valued params (default is 0.00025)\n",
    "\n",
    "assert len(theta0) == len(param_names), \"Mismatch between theta0 and param_names\"\n",
    "\n",
    "# Fixed Parameters\n",
    "fixed_params = {\n",
    "    \"mu_pt\": -0.161175,\n",
    "    \"beta_edu_2_pt\": 0.139161,\n",
    "    \"beta_edu_3_pt\": 0.384016,\n",
    "    \"beta_race_2_pt\": -0.103667,\n",
    "    \"beta_race_3_pt\": -0.028591,\n",
    "    \"beta_age_pt\": 0.049530,\n",
    "    \"beta_agesq_pt\": -0.075483,\n",
    "    \"beta_yeart_pt\": 0.036662,\n",
    "    \"beta_yeartsq_pt\": -0.014824,\n",
    "    \"beta_yeartcb_pt\": 0.000366,\n",
    "    \"beta_yearg_1_pt\": -0.173470,\n",
    "    \"beta_yearg_5_pt\": 0.000000,\n",
    "    \"sigma_pt\": -0.445268,\n",
    "    \"alpha_pt\": 0.966967,\n",
    "    \"gamma_edu_2_pt\": -0.050364,\n",
    "    \"gamma_edu_3_pt\": -0.056926,\n",
    "    \"gamma_race_2_pt\": 0.061106,\n",
    "    \"gamma_race_3_pt\": 0.082067,\n",
    "    \"gamma_age_pt\": 0.016421,\n",
    "    \"gamma_agesq_pt\": -0.017720,\n",
    "    \"gamma_yeart_pt\": -0.003260,\n",
    "    \"gamma_yeartsq_pt\": 0.005503,\n",
    "    \"gamma_yeartcb_pt\": -0.000393,\n",
    "    \"gamma_yearg_1_pt\": -0.002284,\n",
    "    \"gamma_yearg_5_pt\": 0.000000,\n",
    "    \"gamma_child_1_pt\": 0.013950,\n",
    "    \"gamma_child_2_pt\": 0.019279,\n",
    "    \"gamma_child_3_pt\": 0.051607,\n",
    "    \"mu_ft\": -2.391121,\n",
    "    \"beta_edu_2_ft\": 0.529707,\n",
    "    \"beta_edu_3_ft\": 0.878858,\n",
    "    \"beta_race_2_ft\": -0.111668,\n",
    "    \"beta_race_3_ft\": -0.022468,\n",
    "    \"beta_age_ft\": 0.149949,\n",
    "    \"beta_agesq_ft\": -0.173458,\n",
    "    \"beta_yeart_ft\": 0.055035,\n",
    "    \"beta_yeartsq_ft\": -0.092043,\n",
    "    \"beta_yeartcb_ft\": 0.007021,\n",
    "    \"beta_yearg_1_ft\": -0.024542,\n",
    "    \"beta_yearg_5_ft\": 0.000000,\n",
    "    \"sigma_ft\": -0.493030,\n",
    "    \"alpha_ft\": 1.152005,\n",
    "    \"gamma_edu_2_ft\": -0.039952,\n",
    "    \"gamma_edu_3_ft\": 0.052462,\n",
    "    \"gamma_race_2_ft\": 0.025028,\n",
    "    \"gamma_race_3_ft\": 0.064552,\n",
    "    \"gamma_age_ft\": -0.004648,\n",
    "    \"gamma_agesq_ft\": 0.008459,\n",
    "    \"gamma_yeart_ft\": -0.006842,\n",
    "    \"gamma_yeartsq_ft\": 0.006878,\n",
    "    \"gamma_yeartcb_ft\": 0.001803,\n",
    "    \"gamma_yearg_1_ft\": 0.031595,\n",
    "    \"gamma_yearg_5_ft\": 0.000000,\n",
    "    \"gamma_child_1_ft\": 0.024772,\n",
    "    \"gamma_child_2_ft\": 0.093772,\n",
    "    \"gamma_child_3_ft\": 0.187734,\n",
    "    \"a_21\": 0.491443,\n",
    "    \"a_22\": -2.703244,\n",
    "    \"a_11\": 0.000000, # non-identified parameter\n",
    "    \"rho\": 0.500000   # non-identified parameter\n",
    "}\n",
    "\n",
    "def simulate_moments(theta, df_template):\n",
    "\n",
    "    # Merge estimated and fixed parameters\n",
    "    theta_dict = dict(zip(param_names, theta))\n",
    "    params = {**fixed_params, **theta_dict}\n",
    "\n",
    "    def get_param(name):\n",
    "        if name not in params:\n",
    "            raise ValueError(f\"Missing parameter: {name}\")\n",
    "        return params[name]\n",
    "\n",
    "    # Retrieve wage offer function parameters\n",
    "    mu_pt = get_param(\"mu_pt\")\n",
    "    beta_edu_2_pt = get_param(\"beta_edu_2_pt\")\n",
    "    beta_edu_3_pt = get_param(\"beta_edu_3_pt\")\n",
    "    beta_race_2_pt = get_param(\"beta_race_2_pt\")\n",
    "    beta_race_3_pt = get_param(\"beta_race_3_pt\")\n",
    "    beta_age_pt = get_param(\"beta_age_pt\")\n",
    "    beta_agesq_pt = get_param(\"beta_agesq_pt\")\n",
    "    beta_yeart_pt = get_param(\"beta_yeart_pt\")\n",
    "    beta_yeartsq_pt = get_param(\"beta_yeartsq_pt\")\n",
    "    beta_yeartcb_pt = get_param(\"beta_yeartcb_pt\")\n",
    "    beta_yearg_1_pt = get_param(\"beta_yearg_1_pt\")\n",
    "    beta_yearg_5_pt = get_param(\"beta_yearg_5_pt\")\n",
    "    sigma_pt = np.exp(get_param(\"sigma_pt\"))\n",
    "    mu_ft = get_param(\"mu_ft\")\n",
    "    beta_edu_2_ft = get_param(\"beta_edu_2_ft\")\n",
    "    beta_edu_3_ft = get_param(\"beta_edu_3_ft\")\n",
    "    beta_race_2_ft = get_param(\"beta_race_2_ft\")\n",
    "    beta_race_3_ft = get_param(\"beta_race_3_ft\")\n",
    "    beta_age_ft = get_param(\"beta_age_ft\")\n",
    "    beta_agesq_ft = get_param(\"beta_agesq_ft\")\n",
    "    beta_yeart_ft = get_param(\"beta_yeart_ft\")\n",
    "    beta_yeartsq_ft = get_param(\"beta_yeartsq_ft\")\n",
    "    beta_yeartcb_ft = get_param(\"beta_yeartcb_ft\")\n",
    "    beta_yearg_1_ft = get_param(\"beta_yearg_1_ft\")\n",
    "    beta_yearg_5_ft = get_param(\"beta_yearg_5_ft\")\n",
    "    sigma_ft = np.exp(get_param(\"sigma_ft\"))\n",
    "\n",
    "    # Retrieve disutility of work parameters\n",
    "    alpha_pt = get_param(\"alpha_pt\")\n",
    "    gamma_edu_2_pt = get_param(\"gamma_edu_2_pt\")\n",
    "    gamma_edu_3_pt = get_param(\"gamma_edu_3_pt\")\n",
    "    gamma_race_2_pt = get_param(\"gamma_race_2_pt\")\n",
    "    gamma_race_3_pt = get_param(\"gamma_race_3_pt\")\n",
    "    gamma_age_pt = get_param(\"gamma_age_pt\")\n",
    "    gamma_agesq_pt = get_param(\"gamma_agesq_pt\")\n",
    "    gamma_yeart_pt = get_param(\"gamma_yeart_pt\")\n",
    "    gamma_yeartsq_pt = get_param(\"gamma_yeartsq_pt\")\n",
    "    gamma_yeartcb_pt = get_param(\"gamma_yeartcb_pt\")\n",
    "    gamma_yearg_1_pt = get_param(\"gamma_yearg_1_pt\")\n",
    "    gamma_yearg_5_pt = get_param(\"gamma_yearg_5_pt\")\n",
    "    gamma_child_1_pt = get_param(\"gamma_child_1_pt\")\n",
    "    gamma_child_2_pt = get_param(\"gamma_child_2_pt\")\n",
    "    gamma_child_3_pt = get_param(\"gamma_child_3_pt\")\n",
    "    alpha_ft = get_param(\"alpha_ft\")\n",
    "    gamma_edu_2_ft = get_param(\"gamma_edu_2_ft\")\n",
    "    gamma_edu_3_ft = get_param(\"gamma_edu_3_ft\")\n",
    "    gamma_race_2_ft = get_param(\"gamma_race_2_ft\")\n",
    "    gamma_race_3_ft = get_param(\"gamma_race_3_ft\")\n",
    "    gamma_age_ft = get_param(\"gamma_age_ft\")\n",
    "    gamma_agesq_ft = get_param(\"gamma_agesq_ft\")\n",
    "    gamma_yeart_ft = get_param(\"gamma_yeart_ft\")\n",
    "    gamma_yeartsq_ft = get_param(\"gamma_yeartsq_ft\")\n",
    "    gamma_yeartcb_ft = get_param(\"gamma_yeartcb_ft\")\n",
    "    gamma_yearg_1_ft = get_param(\"gamma_yearg_1_ft\")\n",
    "    gamma_yearg_5_ft = get_param(\"gamma_yearg_5_ft\")\n",
    "    gamma_child_1_ft = get_param(\"gamma_child_1_ft\")\n",
    "    gamma_child_2_ft = get_param(\"gamma_child_2_ft\")\n",
    "    gamma_child_3_ft = get_param(\"gamma_child_3_ft\")\n",
    "\n",
    "    # Retrieve utility shocks and utility parameters\n",
    "    a_11 = np.exp(get_param(\"a_11\"))\n",
    "    a_21 = get_param(\"a_21\")\n",
    "    a_22 = np.exp(get_param(\"a_22\"))\n",
    "    rho = get_param(\"rho\")\n",
    "    \n",
    "    # Define variables and stochastic terms\n",
    "    n_obs = len(df_template)\n",
    "    edu = df_template[\"edu\"].values\n",
    "    edu_2 = df_template[\"edu_2\"].values\n",
    "    edu_3 = df_template[\"edu_3\"].values\n",
    "    race = df_template[\"race\"].values\n",
    "    race_2 = df_template[\"race_2\"].values\n",
    "    race_3 = df_template[\"race_3\"].values\n",
    "    age = df_template[\"age\"].values\n",
    "    agesq = df_template[\"agesq\"].values\n",
    "    yeart = df_template[\"yeart\"].values\n",
    "    yeartsq = df_template[\"yeartsq\"].values\n",
    "    yeartcb = df_template[\"yeartcb\"].values\n",
    "    yearg_1 = df_template[\"yearg_1\"].values\n",
    "    yearg_5 = df_template[\"yearg_5\"].values\n",
    "    children = df_template[\"children\"].values\n",
    "    child_1 = df_template[\"child_1\"].values\n",
    "    child_2 = df_template[\"child_2\"].values\n",
    "    child_3 = df_template[\"child_3\"].values\n",
    "    state_cols = sorted([col for col in df_template.columns if col.startswith(\"state_\")])\n",
    "    eta_pt_wage = eta_1[:n_obs]\n",
    "    eta_ft_wage = eta_2[:n_obs]\n",
    "    eta_pt_utility = eta_3[:n_obs]\n",
    "    eta_ft_utility = eta_4[:n_obs]\n",
    "\n",
    "    # Variances and Cholesky decompositions\n",
    "    eps_pt_wage = sigma_pt * eta_pt_wage\n",
    "    eps_ft_wage = sigma_ft * eta_ft_wage\n",
    "    eps_pt_utility = a_11 * eta_pt_utility\n",
    "    eps_ft_utility = a_21 * eta_pt_utility + a_22 * eta_ft_utility\n",
    "\n",
    "    # Part-time wage offer function\n",
    "    lnwage_pt = (\n",
    "        mu_pt\n",
    "        + (beta_edu_2_pt * edu_2)\n",
    "        + (beta_edu_3_pt * edu_3)\n",
    "        + (beta_race_2_pt * race_2)\n",
    "        + (beta_race_3_pt * race_3)\n",
    "        + (beta_age_pt * age)\n",
    "        + (beta_agesq_pt * agesq)\n",
    "        + (beta_yeart_pt * yeart)\n",
    "        + (beta_yeartsq_pt * yeartsq)\n",
    "        + (beta_yeartcb_pt * yeartcb)\n",
    "        + (beta_yearg_1_pt * yearg_1)\n",
    "        + (beta_yearg_5_pt * yearg_5)\n",
    "        + eps_pt_wage\n",
    "    )\n",
    "\n",
    "    wage_pt = np.exp(lnwage_pt)\n",
    "\n",
    "    # Full-time wage offer function\n",
    "    lnwage_ft = (\n",
    "        mu_ft\n",
    "        + (beta_edu_2_ft * edu_2)\n",
    "        + (beta_edu_3_ft * edu_3)\n",
    "        + (beta_race_2_ft * race_2)\n",
    "        + (beta_race_3_ft * race_3)\n",
    "        + (beta_age_ft * age)\n",
    "        + (beta_agesq_ft * agesq)\n",
    "        + (beta_yeart_ft * yeart)\n",
    "        + (beta_yeartsq_ft * yeartsq)\n",
    "        + (beta_yeartcb_ft * yeartcb)\n",
    "        + (beta_yearg_1_ft * yearg_1)\n",
    "        + (beta_yearg_5_ft * yearg_5)\n",
    "        + eps_ft_wage\n",
    "    )\n",
    "\n",
    "    wage_ft = np.exp(lnwage_ft)\n",
    "\n",
    "    # Disutility of work functions\n",
    "    disutil_pt = (\n",
    "        alpha_pt\n",
    "        + (gamma_edu_2_pt * edu_2)\n",
    "        + (gamma_edu_3_pt * edu_3)\n",
    "        + (gamma_race_2_pt * race_2)\n",
    "        + (gamma_race_3_pt * race_3)\n",
    "        + (gamma_age_pt * age)\n",
    "        + (gamma_agesq_pt * agesq)\n",
    "        + (gamma_yeart_pt * yeart)\n",
    "        + (gamma_yeartsq_pt * yeartsq)\n",
    "        + (gamma_yeartcb_pt * yeartcb)\n",
    "        + (gamma_yearg_1_pt * yearg_1)\n",
    "        + (gamma_yearg_5_pt * yearg_5)\n",
    "        + (gamma_child_1_pt * child_1)\n",
    "        + (gamma_child_2_pt * child_2)\n",
    "        + (gamma_child_3_pt * child_3)\n",
    "    )\n",
    "\n",
    "    disutil_ft = (\n",
    "        alpha_ft\n",
    "        + (gamma_edu_2_ft * edu_2)\n",
    "        + (gamma_edu_3_ft * edu_3)\n",
    "        + (gamma_race_2_ft * race_2)\n",
    "        + (gamma_race_3_ft * race_3)\n",
    "        + (gamma_age_ft * age)\n",
    "        + (gamma_agesq_ft * agesq)\n",
    "        + (gamma_yeart_ft * yeart)\n",
    "        + (gamma_yeartsq_ft * yeartsq)\n",
    "        + (gamma_yeartcb_ft * yeartcb)\n",
    "        + (gamma_yearg_1_ft * yearg_1)\n",
    "        + (gamma_yearg_5_ft * yearg_5)\n",
    "        + (gamma_child_1_ft * child_1)\n",
    "        + (gamma_child_2_ft * child_2)\n",
    "        + (gamma_child_3_ft * child_3)\n",
    "    )\n",
    "    \n",
    "    # Initialize df_sim\n",
    "    df_sim = df_template.copy()\n",
    "\n",
    "    # Inputs into tax functions\n",
    "    df_sim[\"wage_pt\"] = wage_pt\n",
    "    df_sim[\"wage_ft\"] = wage_ft\n",
    "    year = int(df_template[\"year\"].iloc[0])\n",
    "    filing_status = \"single\" \n",
    "\n",
    "    # Annualize wages for tax calculation\n",
    "    annual_wage_pt = wage_pt * hours_per_year_pt\n",
    "    annual_wage_ft = wage_ft * hours_per_year_ft\n",
    "\n",
    "    # Calculate federal tax liability (in $/year)\n",
    "    federal_tax_pt = calculate_federal_tax_vectorized(annual_wage_pt, year, filing_status)\n",
    "    federal_tax_ft = calculate_federal_tax_vectorized(annual_wage_ft, year, filing_status)\n",
    "\n",
    "    # Calculate state tax liability (in $/year)\n",
    "    statefips = df_template[\"stfips\"].values\n",
    "    state_tax_pt = calculate_state_tax_vectorized(annual_wage_pt, year, statefips)\n",
    "    state_tax_ft = calculate_state_tax_vectorized(annual_wage_ft, year, statefips)\n",
    "\n",
    "    # Calculate social security + Medicare tax liability (in $/year)\n",
    "    fica_tax_pt = calculate_fica_tax_vectorized(annual_wage_pt, year)\n",
    "    fica_tax_ft = calculate_fica_tax_vectorized(annual_wage_ft, year)\n",
    "\n",
    "    # Compute EITC (in $/year)\n",
    "    num_children = df_template[\"children\"].values\n",
    "    eitc_pt = calculate_eitc_vectorized(annual_wage_pt, year, filing_status, num_children)\n",
    "    eitc_ft = calculate_eitc_vectorized(annual_wage_ft, year, filing_status, num_children)\n",
    "\n",
    "    # Calculate total liability (in $/year)\n",
    "    total_tax_pt = federal_tax_pt + state_tax_pt + fica_tax_pt - eitc_pt\n",
    "    total_tax_ft = federal_tax_ft + state_tax_ft + fica_tax_ft - eitc_ft\n",
    "\n",
    "    # ----------------- DEBUG: Check Tax Year Application -----------------\n",
    "    DEBUG_TAX = False  # ðŸ” Set to True to enable tax year debug output\n",
    "\n",
    "    if DEBUG_TAX:\n",
    "        print(\"\\nðŸ” DEBUG TAX CHECK: Showing 5 sample individuals\")\n",
    "        sample_indices = np.random.choice(len(df_template), size=5, replace=False)\n",
    "        for i in sample_indices:\n",
    "            person_year = df_template[\"year\"].iloc[i]\n",
    "            person_wage = wage_pt[i] * hours_per_year_pt\n",
    "            person_fed_tax = federal_tax_pt[i]\n",
    "            person_statefips = df_template[\"stfips\"].iloc[i]\n",
    "            person_state_tax = state_tax_pt[i]\n",
    "            person_filing = \"single\"  # or use from data if available\n",
    "            print(f\"Obs {i}: Year={person_year}, State={person_statefips}, Filing={person_filing}\")\n",
    "            print(\n",
    "                f\"         Wage = ${person_wage:,.2f}, \"\n",
    "                f\"Federal Tax = ${person_fed_tax:,.2f}, \"\n",
    "                f\"State Tax = ${person_state_tax:,.2f}\"\n",
    "            )\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    # Convert back to hourly by dividing tax by hours/year\n",
    "    wage_pt_aftertax = wage_pt - (total_tax_pt / hours_per_year_pt)\n",
    "    wage_ft_aftertax = wage_ft - (total_tax_ft / hours_per_year_ft)\n",
    "    df_sim[\"wage_pt_aftertax\"] = wage_pt_aftertax\n",
    "    df_sim[\"wage_ft_aftertax\"] = wage_ft_aftertax\n",
    "\n",
    "    # Deflate nominal wages (before and after tax) into real 1983 dollars\n",
    "    df_sim[\"cpi\"] = df_sim[\"year\"].map(CPI_BY_YEAR)\n",
    "    df_sim[\"deflator\"] = 100.0 / df_sim[\"cpi\"]\n",
    "    df_sim[\"real_wage_pt\"] = wage_pt * df_sim[\"deflator\"]\n",
    "    df_sim[\"real_wage_ft\"] = wage_ft * df_sim[\"deflator\"]\n",
    "    df_sim[\"real_wage_pt_aftertax\"] = wage_pt_aftertax * df_sim[\"deflator\"]\n",
    "    df_sim[\"real_wage_ft_aftertax\"] = wage_ft_aftertax * df_sim[\"deflator\"]\n",
    "\n",
    "    # Extract deflated after-tax wages as arrays\n",
    "    real_wage_pt_aftertax = df_sim[\"real_wage_pt_aftertax\"].values\n",
    "    real_wage_ft_aftertax = df_sim[\"real_wage_ft_aftertax\"].values\n",
    "\n",
    "    consump_pt = real_wage_pt_aftertax\n",
    "    consump_ft = real_wage_ft_aftertax\n",
    "\n",
    "    # Clip consumption at zero to avoid negative values\n",
    "    consump_pt = np.maximum(consump_pt, 0)\n",
    "    consump_ft = np.maximum(consump_ft, 0)\n",
    "\n",
    "    # Clip disutilities\n",
    "    disutil_pt_clipped = np.clip(disutil_pt, -10, 10)\n",
    "    disutil_ft_clipped = np.clip(disutil_ft, -10, 10)\n",
    "\n",
    "    # Utility functions\n",
    "    U0 = np.zeros(len(df_template))\n",
    "    U1 = (consump_pt ** (1 - rho)) / (1 - rho) - np.exp(disutil_pt_clipped) + eps_pt_utility\n",
    "    U2 = (consump_ft ** (1 - rho)) / (1 - rho) - np.exp(disutil_ft_clipped) + eps_ft_utility\n",
    "    \n",
    "    df_sim[\"U0\"] = U0\n",
    "    df_sim[\"U1\"] = U1\n",
    "    df_sim[\"U2\"] = U2\n",
    "\n",
    "    choices = np.argmax(np.vstack([U0, U1, U2]), axis=0)\n",
    "    \n",
    "    df_sim[\"sim_nonemp\"] = (choices == 0).astype(int)\n",
    "    df_sim[\"sim_part\"] = (choices == 1).astype(int)\n",
    "    df_sim[\"sim_full\"] = (choices == 2).astype(int)\n",
    "\n",
    "# ------------------------- Generate model moments --------------------------------------------------\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    # Create part-time and full-time log wages\n",
    "    df_sim[\"lnwage_pt_real\"] = np.where(df_sim[\"sim_part\"] == 1, np.log(df_sim[\"real_wage_pt\"]), np.nan)\n",
    "    df_sim[\"lnwage_ft_real\"] = np.where(df_sim[\"sim_full\"] == 1, np.log(df_sim[\"real_wage_ft\"]), np.nan)\n",
    "\n",
    "    # Create simulated employment status variable for masking\n",
    "    df_sim[\"sim_employed_ptft\"] = np.nan\n",
    "    df_sim.loc[df_sim[\"sim_nonemp\"] == 1, \"sim_employed_ptft\"] = 0\n",
    "    df_sim.loc[df_sim[\"sim_part\"] == 1, \"sim_employed_ptft\"] = 1\n",
    "    df_sim.loc[df_sim[\"sim_full\"] == 1, \"sim_employed_ptft\"] = 2\n",
    "\n",
    "    df_pt_sim = df_sim[df_sim[\"sim_part\"] == 1].copy()\n",
    "    df_ft_sim = df_sim[df_sim[\"sim_full\"] == 1].copy()\n",
    "\n",
    "    # Regressors for simulated linear probability models with state and year fixed effects\n",
    "    X_sim = sm.add_constant(\n",
    "        df_sim[[\n",
    "            \"edu_2\", \"edu_3\", \"race_2\", \"race_3\", \"age\", \"agesq\",\n",
    "            \"child_1\", \"child_2\", \"child_3\"\n",
    "        ] + state_cols + year_cols]\n",
    "    )\n",
    "\n",
    "    # Regressors for simulated log wage regressions with state and year fixed effects (PT)\n",
    "    X_pt_sim = sm.add_constant(\n",
    "        df_pt_sim[[\n",
    "            \"edu_2\", \"edu_3\", \"race_2\", \"race_3\",\n",
    "            \"age\", \"agesq\"\n",
    "        ] + state_cols + year_cols]\n",
    "    )\n",
    "\n",
    "    # Regressors for simulated log wage regressions with state and year fixed effects (FT)\n",
    "    X_ft_sim = sm.add_constant(\n",
    "        df_ft_sim[[\n",
    "            \"edu_2\", \"edu_3\", \"race_2\", \"race_3\",\n",
    "            \"age\", \"agesq\"\n",
    "        ] + state_cols + year_cols]\n",
    "    )\n",
    "\n",
    "    # Ensure X's are fully numeric\n",
    "    X_sim = X_sim.astype(float)\n",
    "    X_pt_sim = X_pt_sim.astype(float) \n",
    "    X_ft_sim = X_ft_sim.astype(float)\n",
    "\n",
    "    # Linear probability auxiliary regression: Simulated Employed (PT or FT) vs NE\n",
    "    df_sim[\"sim_employed\"] = ((df_sim[\"sim_part\"] == 1) | (df_sim[\"sim_full\"] == 1)).astype(int)\n",
    "    reg_emp_sim = sm.OLS(df_sim[\"sim_employed\"], X_sim).fit(cov_type=\"HC1\")\n",
    "    se_emp_sim = reg_emp_sim.bse\n",
    "\n",
    "    # Linear probability auxiliary regression: Simulated PT vs NE â€” mask to only keep NE and PT\n",
    "    mask_pt_ne_sim = df_sim[\"sim_employed_ptft\"].isin([0, 1])\n",
    "    reg_emp_pt_sim = sm.OLS(df_sim.loc[mask_pt_ne_sim, \"sim_part\"], X_sim.loc[mask_pt_ne_sim]).fit(cov_type=\"HC1\")\n",
    "    se_emp_pt_sim = reg_emp_pt_sim.bse\n",
    "    \n",
    "    # Linear probability auxiliary regression: Simulated FT vs NE â€” mask to only keep NE and FT\n",
    "    mask_ft_ne_sim = df_sim[\"sim_employed_ptft\"].isin([0, 2])\n",
    "    reg_emp_ft_sim = sm.OLS(df_sim.loc[mask_ft_ne_sim, \"sim_full\"], X_sim.loc[mask_ft_ne_sim]).fit(cov_type=\"HC1\")\n",
    "    se_emp_ft_sim = reg_emp_ft_sim.bse\n",
    "\n",
    "    # Part-time accepted auxiliary wage regression\n",
    "    reg_pt_sim = sm.OLS(df_pt_sim[\"lnwage_pt_real\"], X_pt_sim).fit(cov_type=\"HC1\")\n",
    "    se_pt_sim = reg_pt_sim.bse\n",
    "    resid_pt_sim = df_pt_sim[\"lnwage_pt_real\"] - reg_pt_sim.predict(X_pt_sim)\n",
    "    r2_pt_sim = reg_pt_sim.rsquared\n",
    "    pred_pt_sim = reg_pt_sim.predict(X_pt_sim)\n",
    "\n",
    "    # Full-time accepted wage auxiliary regression\n",
    "    reg_ft_sim = sm.OLS(df_ft_sim[\"lnwage_ft_real\"], X_ft_sim).fit(cov_type=\"HC1\")\n",
    "    se_ft_sim = reg_pt_sim.bse\n",
    "    resid_ft_sim = df_ft_sim[\"lnwage_ft_real\"] - reg_ft_sim.predict(X_ft_sim)\n",
    "    r2_ft_sim = reg_ft_sim.rsquared\n",
    "    pred_ft_sim = reg_ft_sim.predict(X_ft_sim)\n",
    "\n",
    "    m1 = df_sim[\"sim_nonemp\"].mean()\n",
    "    m2 = df_sim[\"sim_part\"].mean()\n",
    "\n",
    "    m3 = reg_emp_pt_sim.params[\"const\"]\n",
    "    m4 = reg_emp_pt_sim.params[\"edu_2\"]\n",
    "    m5 = reg_emp_pt_sim.params[\"edu_3\"]\n",
    "    m6 = reg_emp_pt_sim.params[\"race_2\"]\n",
    "    m7 = reg_emp_pt_sim.params[\"race_3\"]\n",
    "    m8 = reg_emp_pt_sim.params[\"age\"]\n",
    "    m9 = reg_emp_pt_sim.params[\"agesq\"]\n",
    "    m10 = reg_emp_pt_sim.params[\"child_1\"]\n",
    "    m11 = reg_emp_pt_sim.params[\"child_2\"]\n",
    "    m12 = reg_emp_pt_sim.params[\"child_3\"]\n",
    "\n",
    "    m13 = reg_emp_ft_sim.params[\"const\"]\n",
    "    m14 = reg_emp_ft_sim.params[\"edu_2\"]\n",
    "    m15 = reg_emp_ft_sim.params[\"edu_3\"]\n",
    "    m16 = reg_emp_ft_sim.params[\"race_2\"]\n",
    "    m17 = reg_emp_ft_sim.params[\"race_3\"]\n",
    "    m18 = reg_emp_ft_sim.params[\"age\"]\n",
    "    m19 = reg_emp_ft_sim.params[\"agesq\"]\n",
    "    m20 = reg_emp_ft_sim.params[\"child_1\"]\n",
    "    m21 = reg_emp_ft_sim.params[\"child_2\"]\n",
    "    m22 = reg_emp_ft_sim.params[\"child_3\"]\n",
    "\n",
    "    m23 = reg_pt_sim.params[\"const\"]\n",
    "    m24 = reg_pt_sim.params[\"edu_2\"]\n",
    "    m25 = reg_pt_sim.params[\"edu_3\"]\n",
    "    m26 = reg_pt_sim.params[\"race_2\"]\n",
    "    m27 = reg_pt_sim.params[\"race_3\"]\n",
    "    m28 = reg_pt_sim.params[\"age\"]\n",
    "    m29 = reg_pt_sim.params[\"agesq\"]\n",
    "    m30 = np.var(resid_pt_sim, ddof=1)\n",
    "    m31 = r2_pt_sim\n",
    "    \n",
    "    m32 = reg_ft_sim.params[\"const\"]\n",
    "    m33 = reg_ft_sim.params[\"edu_2\"]\n",
    "    m34 = reg_ft_sim.params[\"edu_3\"]\n",
    "    m35 = reg_ft_sim.params[\"race_2\"]\n",
    "    m36 = reg_ft_sim.params[\"race_3\"]\n",
    "    m37 = reg_ft_sim.params[\"age\"]\n",
    "    m38 = reg_ft_sim.params[\"agesq\"]\n",
    "    m39 = np.var(resid_ft_sim, ddof=1)\n",
    "    m40 = r2_ft_sim\n",
    "\n",
    "    m41 = pred_ft_sim.mean() - pred_pt_sim.mean()\n",
    "\n",
    "    m42 = df_pt_sim.loc[df_pt_sim[\"edu\"] == 1, \"lnwage_pt_real\"].mean()\n",
    "    m43 = df_pt_sim.loc[df_pt_sim[\"edu\"] == 2, \"lnwage_pt_real\"].mean()\n",
    "    m44 = df_pt_sim.loc[df_pt_sim[\"edu\"] == 3, \"lnwage_pt_real\"].mean()\n",
    "    m45 = df_pt_sim.loc[df_pt_sim[\"race\"] == 1, \"lnwage_pt_real\"].mean()\n",
    "    m46 = df_pt_sim.loc[df_pt_sim[\"race\"] == 2, \"lnwage_pt_real\"].mean()\n",
    "    m47 = df_pt_sim.loc[df_pt_sim[\"race\"] == 3, \"lnwage_pt_real\"].mean()\n",
    "    m48 = df_pt_sim.loc[df_pt_sim[\"age_group\"] == 1, \"lnwage_pt_real\"].mean()\n",
    "    m49 = df_pt_sim.loc[df_pt_sim[\"age_group\"] == 2, \"lnwage_pt_real\"].mean()\n",
    "    m50 = df_pt_sim.loc[df_pt_sim[\"age_group\"] == 3, \"lnwage_pt_real\"].mean()\n",
    "    m51 = df_pt_sim.loc[df_pt_sim[\"age_group\"] == 4, \"lnwage_pt_real\"].mean()\n",
    "    m52 = df_pt_sim.loc[df_pt_sim[\"age_group\"] == 5, \"lnwage_pt_real\"].mean()\n",
    "    m53 = df_pt_sim.loc[df_pt_sim[\"age_group\"] == 6, \"lnwage_pt_real\"].mean()\n",
    "    m54 = df_pt_sim.loc[df_pt_sim[\"year_group\"] == 1, \"lnwage_pt_real\"].mean()\n",
    "    m55 = df_pt_sim.loc[df_pt_sim[\"year_group\"] == 2, \"lnwage_pt_real\"].mean()\n",
    "    m56 = df_pt_sim.loc[df_pt_sim[\"year_group\"] == 3, \"lnwage_pt_real\"].mean()\n",
    "    m57 = df_pt_sim.loc[df_pt_sim[\"year_group\"] == 4, \"lnwage_pt_real\"].mean()\n",
    "    m58 = df_pt_sim.loc[df_pt_sim[\"year_group\"] == 5, \"lnwage_pt_real\"].mean()\n",
    "    m59 = df_pt_sim.loc[df_pt_sim[\"year_group\"] == 6, \"lnwage_pt_real\"].mean()\n",
    "    m60 = df_pt_sim.loc[df_pt_sim[\"year_group\"] == 7, \"lnwage_pt_real\"].mean()\n",
    "    m61 = df_pt_sim.loc[df_pt_sim[\"year_group\"] == 8, \"lnwage_pt_real\"].mean()\n",
    "\n",
    "    m62 = df_ft_sim.loc[df_ft_sim[\"edu\"] == 1, \"lnwage_ft_real\"].mean()\n",
    "    m63 = df_ft_sim.loc[df_ft_sim[\"edu\"] == 2, \"lnwage_ft_real\"].mean()\n",
    "    m64 = df_ft_sim.loc[df_ft_sim[\"edu\"] == 3, \"lnwage_ft_real\"].mean()\n",
    "    m65 = df_ft_sim.loc[df_ft_sim[\"race\"] == 1, \"lnwage_ft_real\"].mean()\n",
    "    m66 = df_ft_sim.loc[df_ft_sim[\"race\"] == 2, \"lnwage_ft_real\"].mean()\n",
    "    m67 = df_ft_sim.loc[df_ft_sim[\"race\"] == 3, \"lnwage_ft_real\"].mean()\n",
    "    m68 = df_ft_sim.loc[df_ft_sim[\"age_group\"] == 1, \"lnwage_ft_real\"].mean()\n",
    "    m69 = df_ft_sim.loc[df_ft_sim[\"age_group\"] == 2, \"lnwage_ft_real\"].mean()\n",
    "    m70 = df_ft_sim.loc[df_ft_sim[\"age_group\"] == 3, \"lnwage_ft_real\"].mean()\n",
    "    m71 = df_ft_sim.loc[df_ft_sim[\"age_group\"] == 4, \"lnwage_ft_real\"].mean()\n",
    "    m72 = df_ft_sim.loc[df_ft_sim[\"age_group\"] == 5, \"lnwage_ft_real\"].mean()\n",
    "    m73 = df_ft_sim.loc[df_ft_sim[\"age_group\"] == 6, \"lnwage_ft_real\"].mean()\n",
    "    m74 = df_ft_sim.loc[df_ft_sim[\"year_group\"] == 1, \"lnwage_ft_real\"].mean()\n",
    "    m75 = df_ft_sim.loc[df_ft_sim[\"year_group\"] == 2, \"lnwage_ft_real\"].mean()\n",
    "    m76 = df_ft_sim.loc[df_ft_sim[\"year_group\"] == 3, \"lnwage_ft_real\"].mean()\n",
    "    m77 = df_ft_sim.loc[df_ft_sim[\"year_group\"] == 4, \"lnwage_ft_real\"].mean()\n",
    "    m78 = df_ft_sim.loc[df_ft_sim[\"year_group\"] == 5, \"lnwage_ft_real\"].mean()\n",
    "    m79 = df_ft_sim.loc[df_ft_sim[\"year_group\"] == 6, \"lnwage_ft_real\"].mean()\n",
    "    m80 = df_ft_sim.loc[df_ft_sim[\"year_group\"] == 7, \"lnwage_ft_real\"].mean()\n",
    "    m81 = df_ft_sim.loc[df_ft_sim[\"year_group\"] == 8, \"lnwage_ft_real\"].mean()\n",
    "\n",
    "    m82 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"edu\"] == 1), \"sim_part\"].mean()\n",
    "    m83 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"edu\"] == 2), \"sim_part\"].mean()\n",
    "    m84 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"edu\"] == 3), \"sim_part\"].mean()\n",
    "    m85 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"race\"] == 1), \"sim_part\"].mean()\n",
    "    m86 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"race\"] == 2), \"sim_part\"].mean()\n",
    "    m87 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"race\"] == 3), \"sim_part\"].mean()\n",
    "    m88 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"age_group\"] == 1), \"sim_part\"].mean()\n",
    "    m89 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"age_group\"] == 2), \"sim_part\"].mean()\n",
    "    m90 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"age_group\"] == 3), \"sim_part\"].mean()\n",
    "    m91 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"age_group\"] == 4), \"sim_part\"].mean()\n",
    "    m92 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"age_group\"] == 5), \"sim_part\"].mean()\n",
    "    m93 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"age_group\"] == 6), \"sim_part\"].mean()\n",
    "    m94 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"year_group\"] == 1), \"sim_part\"].mean()\n",
    "    m95 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"year_group\"] == 2), \"sim_part\"].mean()\n",
    "    m96 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"year_group\"] == 3), \"sim_part\"].mean()\n",
    "    m97 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"year_group\"] == 4), \"sim_part\"].mean()\n",
    "    m98 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"year_group\"] == 5), \"sim_part\"].mean()\n",
    "    m99 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"year_group\"] == 6), \"sim_part\"].mean()\n",
    "    m100 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"year_group\"] == 7), \"sim_part\"].mean()\n",
    "    m101 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"year_group\"] == 8), \"sim_part\"].mean()\n",
    "    m102 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"child_1\"] == 1), \"sim_part\"].mean()\n",
    "    m103 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"child_2\"] == 1), \"sim_part\"].mean()\n",
    "    m104 = df_sim.loc[mask_pt_ne_sim & (df_sim[\"child_3\"] == 1), \"sim_part\"].mean()\n",
    "\n",
    "    m105 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"edu\"] == 1), \"sim_full\"].mean()\n",
    "    m106 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"edu\"] == 2), \"sim_full\"].mean()\n",
    "    m107 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"edu\"] == 3), \"sim_full\"].mean()\n",
    "    m108 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"race\"] == 1), \"sim_full\"].mean()\n",
    "    m109 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"race\"] == 2), \"sim_full\"].mean()\n",
    "    m110 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"race\"] == 3), \"sim_full\"].mean()\n",
    "    m111 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"age_group\"] == 1), \"sim_full\"].mean()\n",
    "    m112 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"age_group\"] == 2), \"sim_full\"].mean()\n",
    "    m113 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"age_group\"] == 3), \"sim_full\"].mean()\n",
    "    m114 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"age_group\"] == 4), \"sim_full\"].mean()\n",
    "    m115 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"age_group\"] == 5), \"sim_full\"].mean()\n",
    "    m116 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"age_group\"] == 6), \"sim_full\"].mean()\n",
    "    m117 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"year_group\"] == 1), \"sim_full\"].mean()\n",
    "    m118 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"year_group\"] == 2), \"sim_full\"].mean()\n",
    "    m119 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"year_group\"] == 3), \"sim_full\"].mean()\n",
    "    m120 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"year_group\"] == 4), \"sim_full\"].mean()\n",
    "    m121 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"year_group\"] == 5), \"sim_full\"].mean()\n",
    "    m122 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"year_group\"] == 6), \"sim_full\"].mean()\n",
    "    m123 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"year_group\"] == 7), \"sim_full\"].mean()\n",
    "    m124 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"year_group\"] == 8), \"sim_full\"].mean()\n",
    "    m125 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"child_1\"] == 1), \"sim_full\"].mean()\n",
    "    m126 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"child_2\"] == 1), \"sim_full\"].mean()\n",
    "    m127 = df_sim.loc[mask_ft_ne_sim & (df_sim[\"child_3\"] == 1), \"sim_full\"].mean()\n",
    "\n",
    "    simulated_values = {f\"m{i}\": eval(f\"m{i}\") for i in range(1, num_moments + 1)}\n",
    "\n",
    "    return simulated_values, df_sim\n",
    "\n",
    "# ------------------------- Estimate by SMM with Indirect Inference ---------------------------------\n",
    "\n",
    "# SMM objective function\n",
    "def smm_loss(theta, df_sample):\n",
    "    sim_values, _ = simulate_moments(theta, df_sample)\n",
    "    \n",
    "    sim_moments = np.array([sim_values[mname] for _, _, mname in moment_definitions])\n",
    "    actual_moments = np.array([aval for _, aval, _ in moment_definitions])\n",
    "    \n",
    "    diff = sim_moments - actual_moments\n",
    "    \n",
    "    if USE_WEIGHTED_SMM:\n",
    "        weighted_squared_diffs = W * diff**2\n",
    "        return np.sum(weighted_squared_diffs)\n",
    "    else:\n",
    "        return np.sum(diff**2)\n",
    "\n",
    "# Verbose wrapper for loss function to show iteration progress\n",
    "class VerboseLoss:\n",
    "    def __init__(self, base_loss_func, df_sample, param_names=None):\n",
    "        self.loss_func = base_loss_func\n",
    "        self.df_sample = df_sample\n",
    "        self.iteration = 0\n",
    "        self.param_names = param_names\n",
    "\n",
    "    def __call__(self, theta):\n",
    "        start_time = time.time()\n",
    "        loss_val = self.loss_func(theta, self.df_sample)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        self.iteration += 1\n",
    "\n",
    "        if self.param_names:\n",
    "            params_str = \", \".join(f\"{name}={val:.6f}\" for name, val in zip(self.param_names, theta))\n",
    "        else:\n",
    "            params_str = \", \".join(f\"{val:.6f}\" for val in theta)\n",
    "\n",
    "        print(f\"[{self.iteration:03d}] Time={elapsed:.2f}s | {params_str} | Loss={loss_val:.6f}\")\n",
    "        return loss_val\n",
    "\n",
    "def build_initial_simplex(theta0, bump_percent=custom_bump_percent, bump_if_zero=bump_if_zero):\n",
    "    n_params = len(theta0)\n",
    "    simplex = np.tile(theta0, (n_params + 1, 1))\n",
    "    for i in range(n_params):\n",
    "        bump = bump_if_zero if theta0[i] == 0 else bump_percent * abs(theta0[i])\n",
    "        simplex[i + 1, i] += bump\n",
    "    return simplex\n",
    "\n",
    "# Run estimation or skip\n",
    "if SKIP_ESTIMATION:\n",
    "    print(\"â­ï¸ Skipping estimation â€” using initial parameters.\")\n",
    "    base_params = theta0\n",
    "    base_result = type(\"Result\", (object,), {\"x\": theta0})()\n",
    "else:\n",
    "    verbose_loss = VerboseLoss(smm_loss, df_all, param_names)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Build and use custom initial simplex\n",
    "    init_simplex = build_initial_simplex(np.array(theta0))\n",
    "    base_result = minimize(\n",
    "        verbose_loss,\n",
    "        x0=theta0,\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\"disp\": True, \"initial_simplex\": init_simplex}\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_seconds = end_time - start_time\n",
    "    elapsed_minutes = elapsed_seconds / 60\n",
    "    print(f\"\\nâ±ï¸ Estimation completed in {elapsed_seconds:.2f} seconds ({elapsed_minutes:.2f} minutes).\")\n",
    "    print()\n",
    "    base_params = base_result.x\n",
    "\n",
    "theta_hat = base_params\n",
    "for name, val in zip(param_names, base_params):\n",
    "    print(f\"{name:16s} = {val:.6f}\")\n",
    "\n",
    "# Simulate moments and choices at theta_hat\n",
    "simulated_moments, df_sim = simulate_moments(theta_hat, df_all)\n",
    "\n",
    "# --------------------------- CALCULATE STANDARD ERRORS ---------------------------------------------\n",
    "\n",
    "if not SKIP_ESTIMATION:\n",
    "\n",
    "    # DELTA METHOD\n",
    "\n",
    "    if RUN_DELTA:\n",
    "        start_time_se = time.time()\n",
    "\n",
    "        # Always ensure actual moments are correctly float\n",
    "        actual_moments_array = np.array([actual for (_, actual, _) in moment_definitions], dtype=float)\n",
    "\n",
    "        def numerical_jacobian(theta_hat, df_sample, h_vec=None):\n",
    "            k = len(theta_hat)\n",
    "            m = len(moment_definitions)\n",
    "            J = np.zeros((m, k))\n",
    "\n",
    "            # Default to uniform bump if not provided\n",
    "            if h_vec is None:\n",
    "                h_vec = np.full(k, 1e-5)\n",
    "\n",
    "            for i in range(k):\n",
    "                bump = h_vec[i]\n",
    "                theta_up = np.array(theta_hat, dtype=float)\n",
    "                theta_down = np.array(theta_hat, dtype=float)\n",
    "                theta_up[i] += bump\n",
    "                theta_down[i] -= bump\n",
    "\n",
    "                # Simulate moments\n",
    "                m_up_dict = simulate_moments(theta_up, df_sample)[0]\n",
    "                m_down_dict = simulate_moments(theta_down, df_sample)[0]\n",
    "\n",
    "                # Convert dicts to arrays\n",
    "                m_up = np.array([m_up_dict[moment_name] for (_, _, moment_name) in moment_definitions])\n",
    "                m_down = np.array([m_down_dict[moment_name] for (_, _, moment_name) in moment_definitions])\n",
    "\n",
    "                # Numerical derivative\n",
    "                J[:, i] = (m_up - m_down) / (2 * bump)\n",
    "\n",
    "            return J\n",
    "\n",
    "        def estimate_standard_errors(theta_hat, df_sample):\n",
    "            # Customize bump sizes - 1e-3 was lowered from 1e-4\n",
    "            h_vec = np.array([\n",
    "                1e-3 if name.startswith((\"alpha\", \"a_\", \"gamma\"))\n",
    "                else 1e-5\n",
    "                for name in param_names\n",
    "            ])\n",
    "            J = numerical_jacobian(theta_hat, df_sample, h_vec=h_vec)\n",
    "            \n",
    "            sim_dict = simulate_moments(theta_hat, df_sample)[0]\n",
    "            sim_array = np.array([sim_dict[moment_name] for (_, _, moment_name) in moment_definitions])\n",
    "            moment_diff = sim_array - actual_moments_array\n",
    "\n",
    "            if USE_WEIGHTED_SMM:\n",
    "                W_matrix = np.diag(W)\n",
    "                S = np.diag(moment_diff ** 2)\n",
    "                G = J\n",
    "                V = np.linalg.inv(G.T @ W_matrix @ G) @ (G.T @ W_matrix @ S @ W_matrix @ G) @ np.linalg.inv(G.T @ W_matrix @ G)\n",
    "            else:\n",
    "                S = np.diag(moment_diff ** 2)\n",
    "                V = np.linalg.inv(J.T @ J) @ J.T @ S @ J @ np.linalg.inv(J.T @ J)\n",
    "\n",
    "            std_errors = np.sqrt(np.diag(V))\n",
    "            return std_errors\n",
    "\n",
    "        try:\n",
    "            standard_errors = estimate_standard_errors(base_result.x, df_all)\n",
    "            end_time_se = time.time()\n",
    "            duration_sec = end_time_se - start_time_se\n",
    "            duration_min = duration_sec / 60\n",
    "            print(f\"\\nâ±ï¸ Delta Method standard error computation completed in {duration_sec:.2f} seconds ({duration_min:.2f} minutes).\")\n",
    "            print(\"\\nðŸ§® Delta Method Standard Errors:\")\n",
    "            for name, se in zip(param_names, standard_errors):\n",
    "                print(f\"{name:16} = {se:.6f}\")\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            print(\"\\nâŒ Delta Method failed due to a linear algebra error:\")\n",
    "            print(e)\n",
    "            standard_errors = None  # So later checks won't break\n",
    "        except Exception as e:\n",
    "            print(\"\\nâŒ Delta Method failed due to an unexpected error:\")\n",
    "            print(e)\n",
    "            standard_errors = None\n",
    "\n",
    "    #  BOOTSTRAP METHOD\n",
    "\n",
    "    if RUN_BOOTSTRAP:\n",
    "        start_time_bs = time.time()\n",
    "        B = 10  # number of bootstrap replications\n",
    "\n",
    "        def bootstrap_standard_errors(df_sample, theta_start, n_bootstrap):\n",
    "            k = len(theta_start)\n",
    "            boot_estimates = np.zeros((n_bootstrap, k))\n",
    "            for b in range(n_bootstrap):\n",
    "                sample_indices = np.random.choice(len(df_sample), len(df_sample), replace=True)\n",
    "                df_boot = df_sample.iloc[sample_indices].reset_index(drop=True)\n",
    "                result = minimize(smm_loss, x0=theta_start, args=(df_boot,), method=\"Nelder-Mead\", options={\"disp\": False})\n",
    "                boot_estimates[b, :] = result.x\n",
    "                print(f\"[Bootstrap {b+1}/{n_bootstrap}] Completed.\")\n",
    "                print()\n",
    "            return np.std(boot_estimates, axis=0)\n",
    "\n",
    "        bootstrap_errors = bootstrap_standard_errors(df_all, theta_hat, n_bootstrap=B)\n",
    "\n",
    "        end_time_bs = time.time()\n",
    "        duration_sec = end_time_bs - start_time_bs\n",
    "        duration_min = duration_sec / 60\n",
    "        print(f\"\\nâ±ï¸ Bootstrapping standard error computation completed in {duration_sec:.2f} seconds ({duration_min:.2f} minutes).\")\n",
    "\n",
    "        threshold = 1e-8  # Tolerance for \"effectively zero\"\n",
    "        zero_se_mask = (bootstrap_errors < threshold)\n",
    "\n",
    "        if np.any(zero_se_mask):\n",
    "            print(\"\\nâš ï¸ WARNING: Some standard errors are zero or very close to zero!\")\n",
    "            for name, se in zip(param_names, standard_errors):\n",
    "                if se < threshold:\n",
    "                    print(f\" - {name} has SE = {se:.2e}\")\n",
    "        else:\n",
    "            print(\"\\nâœ… All standard errors are above the threshold.\")\n",
    "\n",
    "        print(\"\\nðŸ§® Bootstrapping Standard Errors:\")\n",
    "        for name, se in zip(param_names, bootstrap_errors):\n",
    "            print(f\"{name:16} = {se:.6f}\")\n",
    "\n",
    "    # ------------------ p-VALUE DISPLAY BLOCK -----------------------------------------------------\n",
    "\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    # Choose standard errors and compute p-values\n",
    "    if 'standard_errors' in locals() and standard_errors is not None:\n",
    "        se_used = standard_errors\n",
    "    elif 'bootstrap_errors' in locals() and bootstrap_errors is not None:\n",
    "        se_used = bootstrap_errors\n",
    "    else:\n",
    "        se_used = [np.nan] * len(param_names)\n",
    "\n",
    "    if isinstance(se_used, (list, np.ndarray)):\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(base_params / se_used)))\n",
    "    else:\n",
    "        p_values = [np.nan] * len(param_names)\n",
    "\n",
    "    print(\"\\nðŸ“Š Estimates, Standard Errors, and p-values:\")\n",
    "    print(f\"{'Parameter':16s} {'Estimate':>10} {'Std. Error':>12} {'p-value':>10}\")\n",
    "    print(\"-\" * 50)\n",
    "    for name, est, se, p in zip(param_names, base_params, se_used, p_values):\n",
    "        print(f\"{name:16s} {est:10.6f} {se:12.6f} {p:10.4f}\")\n",
    "\n",
    "    # Save compact CSV\n",
    "    os.makedirs(\"figures\", exist_ok=True)\n",
    "    df_results = pd.DataFrame({\n",
    "        \"Parameter\": param_names,\n",
    "        \"Estimate\": base_params,\n",
    "        \"StdError\": se_used,\n",
    "        \"p_value\": p_values\n",
    "    })\n",
    "    df_results.to_csv(os.path.join(BASE_DIR, \"estimates_with_pvalues.csv\"), index=False)\n",
    "\n",
    "    # ------------------ Build and Save Labeled Table ----------------------------------------------\n",
    "\n",
    "    # Automated readable labels\n",
    "    plot_labels = [name.replace(\"_\", \" \").title() for name in param_names]\n",
    "\n",
    "    # Automated LaTeX labels\n",
    "    latex_labels = [f\"${name.replace('_', '\\\\_')}$\" for name in param_names]\n",
    "\n",
    "    # Automated parameter types based on name\n",
    "    def infer_param_type(name):\n",
    "        if name.startswith(\"mu\"):\n",
    "            return \"mu\"\n",
    "        elif name.startswith(\"beta\"):\n",
    "            return \"beta\"\n",
    "        elif name.startswith(\"sigma\"):\n",
    "            return \"sigma\"\n",
    "        elif name.startswith(\"alpha\"):\n",
    "            return \"alpha\"\n",
    "        elif name.startswith(\"gamma\"):\n",
    "            return \"gamma\"\n",
    "        else:\n",
    "            return \"other\"\n",
    "\n",
    "    param_types = [infer_param_type(name) for name in param_names]\n",
    "\n",
    "    # Final labeled DataFrame\n",
    "    df_results_labeled = pd.DataFrame({\n",
    "        \"Parameter\": param_names,\n",
    "        \"Estimate\": base_params,\n",
    "        \"StdError\": se_used,\n",
    "        \"p_value\": p_values,\n",
    "        \"Label\": plot_labels,\n",
    "        \"LaTeX\": latex_labels,\n",
    "        \"Group\": param_types\n",
    "    })\n",
    "\n",
    "    # Save\n",
    "    diagnostics_path = os.path.join(BASE_DIR, \"estimates_diagnostics.csv\")\n",
    "    df_results_labeled.to_csv(diagnostics_path, index=False)\n",
    "#    print(f\"ðŸ“ Saved labeled diagnostics to {diagnostics_path}\")\n",
    "\n",
    "# ------------------------ Toggles for Diagnostic Plots ---------------------------------------------\n",
    "\n",
    "ANNOTATE_EITC_EXPANSIONS = False       # Set to False to suppress EITC expansion markers\n",
    "\n",
    "EITC_EXPANSION_EVENTS = {\n",
    "    1978: \"Permanent EITC\",\n",
    "    1986: \"TRA86 Expansion\",\n",
    "    1990: \"OBRA90: 2 Child Tier\",\n",
    "    1993: \"OBRA93: Major Boost\",\n",
    "    2001: \"EGTRRA: Marriage Relief\",\n",
    "    2009: \"ARRA: 3 Child Tier\"\n",
    "}\n",
    "\n",
    "PLOT_DIAGNOSTICS = False               # Master toggle to enable or disable three plots on actual data\n",
    "SAVE_LOG_WAGE_PLOT = True\n",
    "SAVE_MEAN_WAGE_PLOT = True\n",
    "SAVE_EMPLOYMENT_SHARE_PLOT = True\n",
    "\n",
    "LOG_WAGE_PLOT_PATH = os.path.join(BASE_DIR, \"wage_log_distributions_overlay.png\")\n",
    "MEAN_WAGE_PLOT_PATH = os.path.join(BASE_DIR, \"mean_raw_wages_by_sector_over_time.png\")\n",
    "EMPLOYMENT_SHARE_PLOT_PATH = os.path.join(BASE_DIR, \"employment_shares_by_type_over_time.png\")\n",
    "\n",
    "PLOT_SIMULATED_WAGE_SUMMARY = False    # Set to True to enable plot for simulated wage data\n",
    "\n",
    "# ------------------------ Print Simulated Choices and Utilities at Estimated Parameters ------------\n",
    "\n",
    "# Print average simulated utilities and plot average simulated utilities by year\n",
    "print()\n",
    "print(\"âœ… Final Mean Utilities:\", df_sim[\"U0\"].mean(), df_sim[\"U1\"].mean(), df_sim[\"U2\"].mean())\n",
    "print()\n",
    "\n",
    "df_sim.groupby(\"year\")[[\"U0\", \"U1\", \"U2\"]].mean().plot(\n",
    "    figsize=(10, 6), title=\"Mean Utilities Over Time\"\n",
    ")\n",
    "plt.ylabel(\"Mean Utility\")\n",
    "plt.grid(True)\n",
    "\n",
    "if ANNOTATE_EITC_EXPANSIONS:\n",
    "    for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "        plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "        plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                 color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR, \"mean_utilities_by_year.png\"), dpi=300)\n",
    "#print(\"âœ… Saved utility plot to mean_utilities_by_year.png\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------- Print Summary of Simulated Wages: Means and Standard Deviations ---------\n",
    "\n",
    "df_sim[\"tax_pt\"] = df_sim[\"wage_pt\"] - df_sim[\"wage_pt_aftertax\"]\n",
    "df_sim[\"tax_ft\"] = df_sim[\"wage_ft\"] - df_sim[\"wage_ft_aftertax\"]\n",
    "df_sim[\"net_to_gross_ratio_pt\"] = df_sim[\"wage_pt_aftertax\"] / df_sim[\"wage_pt\"]\n",
    "df_sim[\"net_to_gross_ratio_ft\"] = df_sim[\"wage_ft_aftertax\"] / df_sim[\"wage_ft\"]\n",
    "df_sim[\"real_wage_pt_net\"] = df_sim[\"real_wage_pt_aftertax\"]\n",
    "df_sim[\"real_wage_ft_net\"] = df_sim[\"real_wage_ft_aftertax\"]\n",
    "\n",
    "wage_diagnostics = {\n",
    "    \"Variable\": [\n",
    "        \"wage_pt\", \"wage_ft\",\n",
    "        \"wage_pt_aftertax\", \"wage_ft_aftertax\",\n",
    "        \"real_wage_pt\", \"real_wage_ft\",\n",
    "        \"real_wage_pt_aftertax\", \"real_wage_ft_aftertax\"\n",
    "    ],\n",
    "    \"Mean\": [\n",
    "        df_sim[\"wage_pt\"].mean(),\n",
    "        df_sim[\"wage_ft\"].mean(),\n",
    "        df_sim[\"wage_pt_aftertax\"].mean(),\n",
    "        df_sim[\"wage_ft_aftertax\"].mean(),\n",
    "        df_sim[\"real_wage_pt\"].mean(),\n",
    "        df_sim[\"real_wage_ft\"].mean(),\n",
    "        df_sim[\"real_wage_pt_aftertax\"].mean(),\n",
    "        df_sim[\"real_wage_ft_aftertax\"].mean()\n",
    "    ],\n",
    "    \"Std Dev\": [\n",
    "        df_sim[\"wage_pt\"].std(),\n",
    "        df_sim[\"wage_ft\"].std(),\n",
    "        df_sim[\"wage_pt_aftertax\"].std(),\n",
    "        df_sim[\"wage_ft_aftertax\"].std(),\n",
    "        df_sim[\"real_wage_pt\"].std(),\n",
    "        df_sim[\"real_wage_ft\"].std(),\n",
    "        df_sim[\"real_wage_pt_aftertax\"].std(),\n",
    "        df_sim[\"real_wage_ft_aftertax\"].std()\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_wage_diag = pd.DataFrame(wage_diagnostics)\n",
    "print(\"\\nðŸ“Š Simulated Wage Diagnostics Summary:\")\n",
    "print()\n",
    "print(df_wage_diag.to_string(index=False))\n",
    "\n",
    "# ------------------------- Compare Simulated and Actual Nominal Gross Hourly Wages Over Time -------\n",
    "\n",
    "# Simulated nominal wages (not deflated)\n",
    "sim_nominal_wages_by_year = pd.DataFrame(index=mean_wage_by_year.index)\n",
    "sim_nominal_wages_by_year[\"Part-Time (Sim, Nominal)\"] = df_sim[df_sim[\"sim_part\"] == 1].groupby(\"year\")[\"wage_pt\"].mean()\n",
    "sim_nominal_wages_by_year[\"Full-Time (Sim, Nominal)\"] = df_sim[df_sim[\"sim_full\"] == 1].groupby(\"year\")[\"wage_ft\"].mean()\n",
    "\n",
    "# Re-inflate actual real wages back to nominal\n",
    "df_actual_nominal = df_all[df_all[\"employed_ptft_robert\"].isin([1, 2]) & df_all[\"wage\"].notna()].copy()\n",
    "df_actual_nominal[\"cpi\"] = df_actual_nominal[\"year\"].map(CPI_BY_YEAR)\n",
    "df_actual_nominal[\"nominal_wage\"] = df_actual_nominal[\"wage\"] * (df_actual_nominal[\"cpi\"] / 100.0)\n",
    "\n",
    "actual_nominal_wages_by_year = df_actual_nominal.groupby([\"year\", \"employed_ptft_robert\"])[\"nominal_wage\"].mean().unstack()\n",
    "actual_nominal_wages_by_year.columns = [\"Part-Time (Actual, Nominal)\", \"Full-Time (Actual, Nominal)\"]\n",
    "\n",
    "# Merge\n",
    "wage_compare_nominal = actual_nominal_wages_by_year.copy()\n",
    "wage_compare_nominal[\"Part-Time (Sim, Nominal)\"] = sim_nominal_wages_by_year[\"Part-Time (Sim, Nominal)\"]\n",
    "wage_compare_nominal[\"Full-Time (Sim, Nominal)\"] = sim_nominal_wages_by_year[\"Full-Time (Sim, Nominal)\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(\n",
    "    wage_compare_nominal.index,\n",
    "    wage_compare_nominal[\"Part-Time (Actual, Nominal)\"],\n",
    "    label=\"Part-Time (Actual, Nominal)\",\n",
    "    linestyle=\"-\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    wage_compare_nominal.index,\n",
    "    wage_compare_nominal[\"Full-Time (Actual, Nominal)\"],\n",
    "    label=\"Full-Time (Actual, Nominal)\",\n",
    "    linestyle=\"-\",\n",
    "    marker=\"s\"\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    wage_compare_nominal.index,\n",
    "    wage_compare_nominal[\"Part-Time (Sim, Nominal)\"],\n",
    "    label=\"Part-Time (Sim, Nominal)\",\n",
    "    linestyle=\"--\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    wage_compare_nominal.index,\n",
    "    wage_compare_nominal[\"Full-Time (Sim, Nominal)\"],\n",
    "    label=\"Full-Time (Sim, Nominal)\",\n",
    "    linestyle=\"--\",\n",
    "    marker=\"s\"\n",
    ")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Mean Gross Hourly Wage ($, Nominal)\")\n",
    "plt.title(\"Actual vs Simulated Nominal Mean Gross Hourly Wage by Sector Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "if ANNOTATE_EITC_EXPANSIONS:\n",
    "    for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "        plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "        plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                 color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR, \"nominal_mean_wage_by_sector_fit.png\"), dpi=300)\n",
    "#print(\"âœ… Saved nominal wage plot to nominal_mean_wage_by_sector_fit.png\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------- Compare Simulated and Actual Real Gross Hourly Wages Over Time ----------\n",
    "\n",
    "# Simulated real wages are already deflated in df_sim: real_wage_pt and real_wage_ft\n",
    "\n",
    "sim_real_wages_by_year = pd.DataFrame(index=mean_wage_by_year.index)\n",
    "sim_real_wages_by_year[\"Part-Time (Sim, Real)\"] = df_sim[df_sim[\"sim_part\"] == 1].groupby(\"year\")[\"real_wage_pt\"].mean()\n",
    "sim_real_wages_by_year[\"Full-Time (Sim, Real)\"] = df_sim[df_sim[\"sim_full\"] == 1].groupby(\"year\")[\"real_wage_ft\"].mean()\n",
    "\n",
    "# Now build actual real wages (already deflated in the dataset)\n",
    "df_actual_real = df_all[df_all[\"employed_ptft_robert\"].isin([1, 2]) & df_all[\"wage\"].notna()].copy()\n",
    "df_actual_real[\"real_wage\"] = df_actual_real[\"wage\"]\n",
    "\n",
    "actual_real_wages_by_year = df_actual_real.groupby([\"year\", \"employed_ptft_robert\"])[\"real_wage\"].mean().unstack()\n",
    "actual_real_wages_by_year.columns = [\"Part-Time (Actual, Real)\", \"Full-Time (Actual, Real)\"]\n",
    "\n",
    "# Merge\n",
    "wage_compare_real = actual_real_wages_by_year.copy()\n",
    "wage_compare_real[\"Part-Time (Sim, Real)\"] = sim_real_wages_by_year[\"Part-Time (Sim, Real)\"]\n",
    "wage_compare_real[\"Full-Time (Sim, Real)\"] = sim_real_wages_by_year[\"Full-Time (Sim, Real)\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(\n",
    "    wage_compare_real.index,\n",
    "    wage_compare_real[\"Part-Time (Actual, Real)\"],\n",
    "    label=\"Part-Time (Actual, Real)\",\n",
    "    linestyle=\"-\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    wage_compare_real.index,\n",
    "    wage_compare_real[\"Full-Time (Actual, Real)\"],\n",
    "    label=\"Full-Time (Actual, Real)\",\n",
    "    linestyle=\"-\",\n",
    "    marker=\"s\"\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    wage_compare_real.index,\n",
    "    wage_compare_real[\"Part-Time (Sim, Real)\"],\n",
    "    label=\"Part-Time (Sim, Real)\",\n",
    "    linestyle=\"--\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    wage_compare_real.index,\n",
    "    wage_compare_real[\"Full-Time (Sim, Real)\"],\n",
    "    label=\"Full-Time (Sim, Real)\",\n",
    "    linestyle=\"--\",\n",
    "    marker=\"s\"\n",
    ")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Mean Gross Hourly Wage (Real 1983 $)\")\n",
    "plt.title(\"Actual vs Simulated Real Mean Gross Hourly Wage by Sector Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "if ANNOTATE_EITC_EXPANSIONS:\n",
    "    for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "        plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "        plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                 color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR, \"real_mean_wage_by_sector_fit.png\"), dpi=300)\n",
    "print(\"âœ… Saved real mean wage fit plot to real_mean_wage_by_sector_fit.png\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------- Compare Simulated and Actual Employment Choices by Year -----------------\n",
    "\n",
    "actual_by_year = df_all.groupby(\"year\")[[\"actual_nonemp\", \"actual_part\", \"actual_full\"]].mean()\n",
    "sim_by_year = df_sim.groupby(\"year\")[[\"sim_nonemp\", \"sim_part\", \"sim_full\"]].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(actual_by_year.index, actual_by_year[\"actual_nonemp\"], label=\"Nonemp (actual)\", linestyle=\"-\")\n",
    "plt.plot(actual_by_year.index, actual_by_year[\"actual_part\"], label=\"Part-time (actual)\", linestyle=\"-\")\n",
    "plt.plot(actual_by_year.index, actual_by_year[\"actual_full\"], label=\"Full-time (actual)\", linestyle=\"-\")\n",
    "plt.plot(sim_by_year.index, sim_by_year[\"sim_nonemp\"], label=\"Nonemp (simulated)\", linestyle=\"--\")\n",
    "plt.plot(sim_by_year.index, sim_by_year[\"sim_part\"], label=\"Part-time (simulated)\", linestyle=\"--\")\n",
    "plt.plot(sim_by_year.index, sim_by_year[\"sim_full\"], label=\"Full-time (simulated)\", linestyle=\"--\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.title(\"Actual vs Simulated Choice Shares by Year (Base Model)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "if ANNOTATE_EITC_EXPANSIONS:\n",
    "    for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "        plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "        plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                 color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "plt.savefig(os.path.join(BASE_DIR, \"choice_shares_by_year.png\"), dpi=300)\n",
    "print(\"âœ… Saved choice shares by year to choice_shares_by_year.png\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------- Diagnostic: Actual vs Simulated Choice Shares by Education Level --------\n",
    "\n",
    "# Group by education level (1 = low, 2 = mid, 3 = high)\n",
    "edu_levels = [1, 2, 3]\n",
    "\n",
    "summary_by_edu = []\n",
    "\n",
    "for level in edu_levels:\n",
    "    row = {\n",
    "        \"Education\": level,\n",
    "        \"Actual Nonemp\": df_all[df_all[\"edu\"] == level][\"actual_nonemp\"].mean(),\n",
    "        \"Simulated Nonemp\": df_sim[df_sim[\"edu\"] == level][\"sim_nonemp\"].mean(),\n",
    "        \"Actual Part-time\": df_all[df_all[\"edu\"] == level][\"actual_part\"].mean(),\n",
    "        \"Simulated Part-time\": df_sim[df_sim[\"edu\"] == level][\"sim_part\"].mean(),\n",
    "        \"Actual Full-time\": df_all[df_all[\"edu\"] == level][\"actual_full\"].mean(),\n",
    "        \"Simulated Full-time\": df_sim[df_sim[\"edu\"] == level][\"sim_full\"].mean(),\n",
    "    }\n",
    "    summary_by_edu.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_by_edu)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nðŸ“Š Choice Shares by Education Level (Actual vs Simulated):\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary table\n",
    "summary_df.to_csv(os.path.join(BASE_DIR, \"choice_shares_by_education.csv\"), index=False)\n",
    "print(\"âœ… Saved grouped summary table to choice_shares_by_education.csv\")\n",
    "\n",
    "# Optional: plot grouped bars\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.12\n",
    "x = range(len(edu_levels))\n",
    "\n",
    "for i, category in enumerate([\"Nonemp\", \"Part-time\", \"Full-time\"]):\n",
    "    actual = summary_df[f\"Actual {category}\"]\n",
    "    sim = summary_df[f\"Simulated {category}\"]\n",
    "    ax.bar([pos + i * bar_width for pos in x], actual, bar_width, label=f\"Actual {category}\")\n",
    "    ax.bar([pos + i * bar_width + 3 * bar_width for pos in x], sim, bar_width, label=f\"Simulated {category}\", alpha=0.7)\n",
    "\n",
    "ax.set_xticks([pos + 1.5 * bar_width for pos in x])\n",
    "ax.set_xticklabels([\"Low\", \"Mid\", \"High\"])\n",
    "ax.set_ylabel(\"Proportion\")\n",
    "ax.set_title(\"Employment Type Shares by Education Level\")\n",
    "ax.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR, \"choice_shares_by_education.png\"), dpi=300)\n",
    "print(\"âœ… Saved grouped bar chart to choice_shares_by_education.png\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------- Compare Simulated and Actual Employment Choices by Age ------------------\n",
    "\n",
    "# Group by age and take means over all years\n",
    "actual_by_age = df_all.groupby(\"age\")[[\"actual_nonemp\", \"actual_part\", \"actual_full\"]].mean()\n",
    "sim_by_age = df_sim.groupby(\"age\")[[\"sim_nonemp\", \"sim_part\", \"sim_full\"]].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(actual_by_age.index, actual_by_age[\"actual_nonemp\"], label=\"Nonemp (actual)\", linestyle=\"-\")\n",
    "plt.plot(actual_by_age.index, actual_by_age[\"actual_part\"], label=\"Part-time (actual)\", linestyle=\"-\")\n",
    "plt.plot(actual_by_age.index, actual_by_age[\"actual_full\"], label=\"Full-time (actual)\", linestyle=\"-\")\n",
    "plt.plot(sim_by_age.index, sim_by_age[\"sim_nonemp\"], label=\"Nonemp (simulated)\", linestyle=\"--\")\n",
    "plt.plot(sim_by_age.index, sim_by_age[\"sim_part\"], label=\"Part-time (simulated)\", linestyle=\"--\")\n",
    "plt.plot(sim_by_age.index, sim_by_age[\"sim_full\"], label=\"Full-time (simulated)\", linestyle=\"--\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.title(\"Actual vs Simulated Choice Shares by Age (Averaged Over Years)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR, \"choice_shares_by_age.png\"), dpi=300)\n",
    "print(\"âœ… Saved choice shares by age to choice_shares_by_age.png\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Diagnostic: Actual vs Simulated Choice Shares by Number of Children ----------\n",
    "\n",
    "# Define child bins\n",
    "df_all[\"child_bin\"] = df_all[\"children\"].clip(upper=3)\n",
    "df_sim[\"child_bin\"] = df_sim[\"children\"].clip(upper=3)\n",
    "\n",
    "child_bins = [0, 1, 2, 3]\n",
    "summary_by_child = []\n",
    "\n",
    "for val in child_bins:\n",
    "    row = {\n",
    "        \"Children\": f\"{val}\" if val < 3 else \"3+\",\n",
    "        \"Actual Nonemp\": df_all[df_all[\"child_bin\"] == val][\"actual_nonemp\"].mean(),\n",
    "        \"Simulated Nonemp\": df_sim[df_sim[\"child_bin\"] == val][\"sim_nonemp\"].mean(),\n",
    "        \"Actual Part-time\": df_all[df_all[\"child_bin\"] == val][\"actual_part\"].mean(),\n",
    "        \"Simulated Part-time\": df_sim[df_sim[\"child_bin\"] == val][\"sim_part\"].mean(),\n",
    "        \"Actual Full-time\": df_all[df_all[\"child_bin\"] == val][\"actual_full\"].mean(),\n",
    "        \"Simulated Full-time\": df_sim[df_sim[\"child_bin\"] == val][\"sim_full\"].mean(),\n",
    "    }\n",
    "    summary_by_child.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_by_child)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nðŸ“Š Choice Shares by Number of Children (Actual vs Simulated):\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary table\n",
    "summary_df.to_csv(os.path.join(BASE_DIR, \"choice_shares_by_children.csv\"), index=False)\n",
    "print(\"âœ… Saved grouped summary table to choice_shares_by_children.csv\")\n",
    "\n",
    "# Optional: plot grouped bars\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.12\n",
    "x = range(len(child_bins))\n",
    "\n",
    "for i, category in enumerate([\"Nonemp\", \"Part-time\", \"Full-time\"]):\n",
    "    actual = summary_df[f\"Actual {category}\"]\n",
    "    sim = summary_df[f\"Simulated {category}\"]\n",
    "    ax.bar([pos + i * bar_width for pos in x], actual, bar_width, label=f\"Actual {category}\")\n",
    "    ax.bar([pos + i * bar_width + 3 * bar_width for pos in x], sim, bar_width, label=f\"Simulated {category}\", alpha=0.7)\n",
    "\n",
    "ax.set_xticks([pos + 1.5 * bar_width for pos in x])\n",
    "ax.set_xticklabels([\"0\", \"1\", \"2\", \"3+\"])\n",
    "ax.set_ylabel(\"Proportion\")\n",
    "ax.set_title(\"Employment Type Shares by Number of Children\")\n",
    "ax.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR, \"choice_shares_by_children.png\"), dpi=300)\n",
    "print(\"âœ… Saved grouped bar chart to choice_shares_by_children.png\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Diagnostic: Actual vs Simulated Choice Shares by Race --------------------\n",
    "\n",
    "# Define race categories\n",
    "race_labels = {\n",
    "    1: \"White\",\n",
    "    2: \"Black\",\n",
    "    3: \"Other\"\n",
    "}\n",
    "race_values = sorted(race_labels.keys())\n",
    "\n",
    "summary_by_race = []\n",
    "\n",
    "for val in race_values:\n",
    "    row = {\n",
    "        \"Race\": race_labels[val],\n",
    "        \"Actual Nonemp\": df_all[df_all[\"race\"] == val][\"actual_nonemp\"].mean(),\n",
    "        \"Simulated Nonemp\": df_sim[df_sim[\"race\"] == val][\"sim_nonemp\"].mean(),\n",
    "        \"Actual Part-time\": df_all[df_all[\"race\"] == val][\"actual_part\"].mean(),\n",
    "        \"Simulated Part-time\": df_sim[df_sim[\"race\"] == val][\"sim_part\"].mean(),\n",
    "        \"Actual Full-time\": df_all[df_all[\"race\"] == val][\"actual_full\"].mean(),\n",
    "        \"Simulated Full-time\": df_sim[df_sim[\"race\"] == val][\"sim_full\"].mean(),\n",
    "    }\n",
    "    summary_by_race.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_by_race)\n",
    "\n",
    "# Print the table\n",
    "print(\"\\nðŸ“Š Choice Shares by Race (Actual vs Simulated):\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary table\n",
    "summary_df.to_csv(os.path.join(BASE_DIR, \"choice_shares_by_race.csv\"), index=False)\n",
    "print(\"âœ… Saved grouped summary table to choice_shares_by_race.csv\")\n",
    "\n",
    "# Optional: plot grouped bars\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.12\n",
    "x = range(len(race_values))\n",
    "\n",
    "for i, category in enumerate([\"Nonemp\", \"Part-time\", \"Full-time\"]):\n",
    "    actual = summary_df[f\"Actual {category}\"]\n",
    "    sim = summary_df[f\"Simulated {category}\"]\n",
    "    ax.bar([pos + i * bar_width for pos in x], actual, bar_width, label=f\"Actual {category}\")\n",
    "    ax.bar([pos + i * bar_width + 3 * bar_width for pos in x], sim, bar_width, label=f\"Simulated {category}\", alpha=0.7)\n",
    "\n",
    "ax.set_xticks([pos + 1.5 * bar_width for pos in x])\n",
    "ax.set_xticklabels([race_labels[val] for val in race_values])\n",
    "ax.set_ylabel(\"Proportion\")\n",
    "ax.set_title(\"Employment Type Shares by Race\")\n",
    "ax.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(BASE_DIR, \"choice_shares_by_race.png\"), dpi=300)\n",
    "print(\"âœ… Saved grouped bar chart to choice_shares_by_race.png\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------- Build Moment Diagnostics ------------------------------------------------\n",
    "\n",
    "# Collect actual and simulated moments\n",
    "actual_values = np.array([actual for (_, actual, _) in moment_definitions])\n",
    "simulated_values_array = np.array([simulated_moments[moment_name] for (_, _, moment_name) in moment_definitions])\n",
    "moment_labels = [label for (label, _, _) in moment_definitions]\n",
    "\n",
    "# Compute differences\n",
    "moment_diff = simulated_values_array - actual_values\n",
    "\n",
    "# Create diagnostics table\n",
    "diagnostics = pd.DataFrame({\n",
    "    \"Moment\": moment_labels,\n",
    "    \"Actual\": actual_values,\n",
    "    \"Simulated\": simulated_values_array,\n",
    "    \"Difference\": moment_diff\n",
    "})\n",
    "\n",
    "# Print diagnostics\n",
    "print(\"\\nðŸ“Š Base Model Moment Diagnostics:\")\n",
    "print(diagnostics.to_string(index=False))\n",
    "print(\"\\nSum of Squared Differences:\", np.sum(moment_diff**2))\n",
    "print()\n",
    "\n",
    "# Save diagnostics\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "diagnostics.to_csv(os.path.join(BASE_DIR, \"moment_diagnostics.csv\"), index=False)\n",
    "#print(\"âœ… Saved diagnostics to moment_diagnostics.csv\")\n",
    "\n",
    "# ------------------------- Print Moment Weights ----------------------------------------------------\n",
    "\n",
    "print(\"Index | Raw Weight       | Mean-Normalized  | Log-Normalized  | Manual-Scaled   | Final W Used\")\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "for i in range(num_moments):\n",
    "    label = moment_definitions[i][2]\n",
    "    w_base = W_base[i]\n",
    "    w_mean = W_mean_normalized[i]\n",
    "    w_log = W_log_normalized[i]\n",
    "    w_manual = W_manual_scaled[i] if 'W_manual_scaled' in locals() else float('nan')\n",
    "    w_final = W[i]\n",
    "    print(f\"{i+1:5d} | {w_base:15.3f} | {w_mean:15.6f} | {w_log:15.6f} | {w_manual:15.6f} | {w_final:15.6f}  {label}\")\n",
    "\n",
    "# ------------------------- Plots for Actual Data ---------------------------------------------------\n",
    "\n",
    "if PLOT_DIAGNOSTICS:\n",
    "\n",
    "    # Plot original and winsorized log wage distributions\n",
    "    log_wage_original = np.log(df_all[\"wage_original\"][df_all[\"wage_original\"] > 0])\n",
    "    log_wage_winsorized = np.log(df_all[\"wage\"][df_all[\"wage\"] > 0])\n",
    "\n",
    "    bin_edges = np.histogram_bin_edges(\n",
    "        np.concatenate([log_wage_original, log_wage_winsorized]), bins=100\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(log_wage_original, bins=bin_edges, color=\"steelblue\", label=\"Original\", alpha=0.6)\n",
    "    sns.histplot(log_wage_winsorized, bins=bin_edges, color=\"seagreen\", label=\"Winsorized\", alpha=0.6)\n",
    "\n",
    "    plt.title(\"Overlay: Log Wage Distributions (Original vs Winsorized)\")\n",
    "    plt.xlabel(\"Log Wage\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_LOG_WAGE_PLOT:\n",
    "        plt.savefig(LOG_WAGE_PLOT_PATH)\n",
    "        print(f\"âœ… Saved overlay log wage histogram to {LOG_WAGE_PLOT_PATH}\")\n",
    "        plt.show()\n",
    "\n",
    "    # Plot Actual Mean Real Gross Hourly Wages by Sector and Year\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(mean_wage_by_year.index, mean_wage_by_year[\"Part-Time\"], label=\"Part-Time\", linestyle=\"--\", marker=\"o\")\n",
    "    plt.plot(mean_wage_by_year.index, mean_wage_by_year[\"Full-Time\"], label=\"Full-Time\", linestyle=\"-\", marker=\"s\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Actual Mean Gross Hourly Wage (Real 1983 $)\")\n",
    "    plt.title(\"Actual Mean Gross Hourly Wage by Sector Over Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    if ANNOTATE_EITC_EXPANSIONS:\n",
    "        for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "            plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "            plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                     color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_MEAN_WAGE_PLOT:\n",
    "        plt.savefig(MEAN_WAGE_PLOT_PATH, dpi=300)\n",
    "        print(f\"âœ… Saved to {MEAN_WAGE_PLOT_PATH}\")\n",
    "        plt.show()\n",
    "\n",
    "    # Plot Actual Employment Shares by Type Over Time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(employment_shares.index, employment_shares[\"actual_nonemp\"], label=\"Non-Employed\", linestyle=\"-\", marker=\"o\")\n",
    "    plt.plot(employment_shares.index, employment_shares[\"actual_part\"], label=\"Part-Time\", linestyle=\"--\", marker=\"s\")\n",
    "    plt.plot(employment_shares.index, employment_shares[\"actual_full\"], label=\"Full-Time\", linestyle=\":\", marker=\"^\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Share of Individuals\")\n",
    "    plt.title(\"Actual Employment Shares by Type Over Time\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    if ANNOTATE_EITC_EXPANSIONS:\n",
    "        for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "            plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "            plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                     color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_EMPLOYMENT_SHARE_PLOT:\n",
    "        plt.savefig(EMPLOYMENT_SHARE_PLOT_PATH, dpi=300)\n",
    "        print(f\"âœ… Saved to {EMPLOYMENT_SHARE_PLOT_PATH}\")\n",
    "        plt.show()\n",
    "\n",
    "# Simulated Wage Plotting\n",
    "\n",
    "if PLOT_SIMULATED_WAGE_SUMMARY:\n",
    "    # Group by year (Simulated Data)\n",
    "    df_yearly = df_sim.groupby(\"year\").agg({\n",
    "        \"wage_pt\": \"mean\",\n",
    "        \"wage_ft\": \"mean\",\n",
    "        \"wage_pt_aftertax\": \"mean\",\n",
    "        \"wage_ft_aftertax\": \"mean\",\n",
    "        \"real_wage_pt\": \"mean\",\n",
    "        \"real_wage_ft\": \"mean\",\n",
    "        \"tax_pt\": \"mean\",\n",
    "        \"tax_ft\": \"mean\",\n",
    "        \"net_to_gross_ratio_pt\": \"mean\",\n",
    "        \"net_to_gross_ratio_ft\": \"mean\",\n",
    "        \"cpi\": \"mean\"\n",
    "    }).reset_index()\n",
    "\n",
    "    # Group by year for real net wages\n",
    "    df_net_wages = df_sim.groupby(\"year\")[[\"real_wage_pt_net\", \"real_wage_ft_net\"]].mean().reset_index()\n",
    "\n",
    "    # Plot 1: Net-to-Gross Ratios (Simulated Data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df_yearly[\"year\"], df_yearly[\"net_to_gross_ratio_pt\"], label=\"PT Net-to-Gross\")\n",
    "    plt.plot(df_yearly[\"year\"], df_yearly[\"net_to_gross_ratio_ft\"], label=\"FT Net-to-Gross\")\n",
    "    plt.title(\"Net-to-Gross Wage Ratios Over Time (Simulated Data)\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Ratio\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    if ANNOTATE_EITC_EXPANSIONS:\n",
    "        for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "            plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "            plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                     color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(BASE_DIR, \"net_to_gross_ratios_over_time.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 2: Real Gross Wages (Simulated Data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df_yearly[\"year\"], df_yearly[\"real_wage_pt\"], label=\"PT Real Wage (Gross)\")\n",
    "    plt.plot(df_yearly[\"year\"], df_yearly[\"real_wage_ft\"], label=\"FT Real Wage (Gross)\")\n",
    "    plt.title(\"Real Gross Wages Over Time (Simulated Data)\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Real Wage\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    if ANNOTATE_EITC_EXPANSIONS:\n",
    "        for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "            plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "            plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                     color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(BASE_DIR, \"real_gross_wages_over_time.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 3: Tax Burden (Simulated Data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df_yearly[\"year\"], df_yearly[\"tax_pt\"], label=\"PT Tax\")\n",
    "    plt.plot(df_yearly[\"year\"], df_yearly[\"tax_ft\"], label=\"FT Tax\")\n",
    "    plt.title(\"Tax Burden Over Time (Simulated Data)\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Tax ($/hr)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(BASE_DIR, \"tax_burden_over_time.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 4: Real Net Wages (Simulated Data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df_net_wages[\"year\"], df_net_wages[\"real_wage_pt_net\"], label=\"PT Real Wage (Net)\")\n",
    "    plt.plot(df_net_wages[\"year\"], df_net_wages[\"real_wage_ft_net\"], label=\"FT Real Wage (Net)\")\n",
    "    plt.title(\"Real Net Wages Over Time (Simulated Data)\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Real Net Wage ($)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    if ANNOTATE_EITC_EXPANSIONS:\n",
    "        for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "            plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "            plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                     color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(BASE_DIR, \"real_net_wages_over_time.png\")\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"âœ… Saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 5: CPI Trend (Actual Data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Select correct CPI series based on toggle\n",
    "    if USE_R_CPI:\n",
    "        cpi_label = \"R-CPI-U-RS (1977=100)\"\n",
    "        cpi_data = CPI_1977_BASE\n",
    "    else:\n",
    "        cpi_label = \"CPI-U (1983=100)\"\n",
    "        cpi_data = CPI_1983_BASE\n",
    "\n",
    "    # Sort by year to ensure proper plotting\n",
    "    years_sorted = sorted(cpi_data.keys())\n",
    "    cpi_values = [cpi_data[y] for y in years_sorted]\n",
    "\n",
    "    plt.plot(years_sorted, cpi_values, label=cpi_label, color=\"purple\")\n",
    "    plt.title(f\"CPI Over Time ({cpi_label})\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"CPI Index\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    if ANNOTATE_EITC_EXPANSIONS:\n",
    "        for year, label in EITC_EXPANSION_EVENTS.items():\n",
    "            plt.axvline(x=year, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "            plt.text(year + 0.1, plt.ylim()[1]*0.9, label, rotation=90,\n",
    "                     color=\"red\", fontsize=8, verticalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(BASE_DIR, \"cpi_over_time.png\"))\n",
    "    plt.show()    \n",
    "# --------------------------------------------------END PROGRAM--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a71f0b-76b8-484d-a3fa-22f0dbbc56aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
